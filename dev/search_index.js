var documenterSearchIndex = {"docs":
[{"location":"guide/sparse_matrix_qp/#Sparse-Matrix-QP","page":"Sparse Matrix QP","title":"Sparse Matrix QP","text":"The sparse matrix Q operator is the default and most general way to represent quadratic objectives in HPRQP. It's suitable for any sparse positive semidefinite matrix.","category":"section"},{"location":"guide/sparse_matrix_qp/#When-to-Use","page":"Sparse Matrix QP","title":"When to Use","text":"Use the sparse matrix operator when:\n\nYou have a general quadratic programming problem\nYour Q matrix is sparse (not dense)\nYou don't have special structure (LASSO, QAP, etc.)\nYou want the simplest, most straightforward approach","category":"section"},{"location":"guide/sparse_matrix_qp/#Basic-Usage","page":"Sparse Matrix QP","title":"Basic Usage","text":"using HPRQP\nusing SparseArrays\n\n# Define a sparse positive semidefinite matrix\nQ = sparse([\n    2.0  0.5  0.0  0.0;\n    0.5  2.0  0.5  0.0;\n    0.0  0.5  2.0  0.5;\n    0.0  0.0  0.5  2.0\n])\n\n# Linear term\nc = [1.0, 2.0, 3.0, 4.0]\n\n# Constraints (simple box constraints for this example)\nA = sparse(zeros(0, 4))\nAL = Float64[]\nAU = Float64[]\nl = zeros(4)\nu = fill(10.0, 4)\n\n# Build and solve\nmodel = build_from_QAbc(Q, A, c, AL, AU, l, u)\n\nparams = HPRQP_parameters()\nresult = optimize(model, params)","category":"section"},{"location":"guide/sparse_matrix_qp/#Creating-Sparse-Q-Matrices","page":"Sparse Matrix QP","title":"Creating Sparse Q Matrices","text":"","category":"section"},{"location":"guide/sparse_matrix_qp/#From-Dense-Matrices","page":"Sparse Matrix QP","title":"From Dense Matrices","text":"using SparseArrays\n\n# Convert dense to sparse\nQ_dense = [2.0 0.5; 0.5 2.0]\nQ_sparse = sparse(Q_dense)\n\n# HPRQP will also convert automatically\nmodel = build_from_QAbc(Q_dense, A, c, AL, AU, l, u)  # Works but issues warning","category":"section"},{"location":"guide/sparse_matrix_qp/#Building-Sparse-Matrices-Directly","page":"Sparse Matrix QP","title":"Building Sparse Matrices Directly","text":"using SparseArrays\n\nn = 100\n\n# Tridiagonal matrix\nmain_diag = fill(2.0, n)\noff_diag = fill(0.5, n-1)\nQ = spdiagm(0 => main_diag, 1 => off_diag, -1 => off_diag)\n\n# Random sparse matrix (make it positive semidefinite)\nH = sprandn(n, n, 0.1)  # 10% density\nQ = H' * H  # Q = H'H is positive semidefinite","category":"section"},{"location":"guide/sparse_matrix_qp/#Block-Diagonal-Structure","page":"Sparse Matrix QP","title":"Block Diagonal Structure","text":"using SparseArrays\nusing LinearAlgebra\n\n# Create block diagonal Q\nn_blocks = 10\nblock_size = 5\n\nblocks = [spdiagm(0 => rand(block_size)) for _ in 1:n_blocks]\nQ = blockdiag(blocks...)","category":"section"},{"location":"guide/sparse_matrix_qp/#Ensuring-Positive-Semidefiniteness","page":"Sparse Matrix QP","title":"Ensuring Positive Semidefiniteness","text":"Q must be positive semidefinite for convex QP. Here are ways to ensure this:","category":"section"},{"location":"guide/sparse_matrix_qp/#Method-1:-Form-Q-H'H","page":"Sparse Matrix QP","title":"Method 1: Form Q = H'H","text":"H = sprandn(n, n, 0.1)\nQ = H' * H  # Always positive semidefinite","category":"section"},{"location":"guide/sparse_matrix_qp/#Method-2:-Add-Regularization","page":"Sparse Matrix QP","title":"Method 2: Add Regularization","text":"Q_indefinite = ... # Some matrix\nλ = 1e-6\nQ = Q_indefinite + λ * I  # Make positive definite","category":"section"},{"location":"guide/sparse_matrix_qp/#Method-3:-Symmetric-Part-of-A'A","page":"Sparse Matrix QP","title":"Method 3: Symmetric Part of A'A","text":"A = randn(m, n)\nQ = sparse((A' * A + (A' * A)') / 2)  # Ensure symmetry","category":"section"},{"location":"guide/sparse_matrix_qp/#Performance-Considerations","page":"Sparse Matrix QP","title":"Performance Considerations","text":"","category":"section"},{"location":"guide/sparse_matrix_qp/#Sparsity-Pattern","page":"Sparse Matrix QP","title":"Sparsity Pattern","text":"The performance depends heavily on sparsity:\n\nusing SparseArrays\n\nn = 1000\n\n# Diagonal (very sparse)\nQ_diag = spdiagm(0 => rand(n))\nprintln(\"Diagonal nnz: \", nnz(Q_diag))  # 1000\n\n# Tridiagonal  \nQ_tri = spdiagm(0 => rand(n), 1 => rand(n-1), -1 => rand(n-1))\nprintln(\"Tridiagonal nnz: \", nnz(Q_tri))  # ~3000\n\n# Banded\nbandwidth = 10\nQ_band = spdiagm([k => rand(n - abs(k)) for k in -bandwidth:bandwidth]...)\nprintln(\"Banded nnz: \", nnz(Q_band))  # ~20,000\n\n# Random sparse\ndensity = 0.01\nH = sprandn(n, n, density)\nQ_random = H' * H\nprintln(\"Random nnz: \", nnz(Q_random))  # ~100,000","category":"section"},{"location":"guide/sparse_matrix_qp/#Dense-vs-Sparse-Threshold","page":"Sparse Matrix QP","title":"Dense vs Sparse Threshold","text":"As a rule of thumb:\n\nSparse (< 10% density): Use sparse matrix operator\nDense (> 50% density): Consider if problem can be reformulated\nMedium (10-50% density): Test both, sparse usually better\n\nusing SparseArrays\n\nn = 1000\ndensity = 0.05  # 5% density\n\nH = sprandn(n, n, density)\nQ = H' * H\n\nprintln(\"Matrix size: \", n, \"×\", n)\nprintln(\"Density: \", nnz(Q) / (n^2) * 100, \"%\")\nprintln(\"Memory (sparse): \", Base.summarysize(Q) / 1e6, \" MB\")\nprintln(\"Memory (dense): \", 8 * n^2 / 1e6, \" MB\")","category":"section"},{"location":"guide/sparse_matrix_qp/#Common-Patterns","page":"Sparse Matrix QP","title":"Common Patterns","text":"","category":"section"},{"location":"guide/sparse_matrix_qp/#Portfolio-Optimization","page":"Sparse Matrix QP","title":"Portfolio Optimization","text":"using SparseArrays\nusing LinearAlgebra\n\n# Covariance matrix (often sparse for large portfolios)\nn_assets = 100\n\n# Block diagonal covariance (assets grouped by sector)\nsector_sizes = [20, 30, 25, 25]\nsectors = []\nfor s in sector_sizes\n    Σ_sector = rand(s, s)\n    Σ_sector = (Σ_sector + Σ_sector') / 2  # Symmetric\n    Σ_sector += 2I  # Positive definite\n    push!(sectors, Σ_sector)\nend\n\nQ = 2 * blockdiag([sparse(s) for s in sectors]...)  # Factor of 2 for QP form\n\n# Expected returns\nμ = rand(n_assets)\n\n# Build QP: min 0.5*x'Qx - μ'x subject to sum(x) = 1, x >= 0\nA = sparse(ones(1, n_assets))\nAL = [1.0]\nAU = [1.0]\nc = -μ\nl = zeros(n_assets)\nu = ones(n_assets)\n\nmodel = build_from_QAbc(Q, A, c, AL, AU, l, u)","category":"section"},{"location":"guide/sparse_matrix_qp/#Support-Vector-Machine-(Dual)","page":"Sparse Matrix QP","title":"Support Vector Machine (Dual)","text":"using SparseArrays\n\n# SVM dual: min 0.5*α'Qα - 1'α where Q[i,j] = y[i]*y[j]*K[i,j]\nm = 1000  # Training samples\n\ny = rand([-1, 1], m)  # Labels\nK = exp.(-0.1 * (rand(m) .- rand(m)').^2)  # RBF kernel (dense)\n\n# Q is often dense for kernel methods, but can sparsify\nQ_full = sparse([(y[i] * y[j] * K[i,j]) for i in 1:m, j in 1:m])\n\n# Sparsify by thresholding small entries\nthreshold = 1e-3\nQ = sparse(Q_full .* (abs.(Q_full) .> threshold))\n\nprintln(\"Sparsified to \", nnz(Q) / length(Q) * 100, \"% density\")","category":"section"},{"location":"guide/sparse_matrix_qp/#Regularized-Least-Squares-(Non-LASSO)","page":"Sparse Matrix QP","title":"Regularized Least Squares (Non-LASSO)","text":"using SparseArrays\n\n# Ridge regression: min ||Ax - b||² + λ||Dx||²\n# where D is a regularization matrix (e.g., finite differences)\n\nm, n = 100, 50\nA = randn(m, n)\nb = randn(m)\nλ = 0.1\n\n# First-order finite difference operator\nD = spdiagm(0 => ones(n-1), 1 => -ones(n-1))\n\n# Q = A'A + λD'D\nQ = sparse(A' * A + λ * (D' * D))\n\nc = -A' * b","category":"section"},{"location":"guide/sparse_matrix_qp/#Troubleshooting","page":"Sparse Matrix QP","title":"Troubleshooting","text":"","category":"section"},{"location":"guide/sparse_matrix_qp/#Matrix-Not-Positive-Semidefinite","page":"Sparse Matrix QP","title":"Matrix Not Positive Semidefinite","text":"If you get convergence issues or unbounded solutions:\n\nusing LinearAlgebra\n\n# Check if Q is positive semidefinite\neigvals_Q = eigvals(Matrix(Q))\nif minimum(eigvals_Q) < -1e-10\n    @warn \"Q has negative eigenvalues, not positive semidefinite\"\n    \n    # Fix by adding regularization\n    λ = abs(minimum(eigvals_Q)) + 1e-6\n    Q = Q + λ * I\nend","category":"section"},{"location":"guide/sparse_matrix_qp/#Out-of-Memory","page":"Sparse Matrix QP","title":"Out of Memory","text":"For very large sparse matrices:\n\n# Use GPU to offload memory\nparams = HPRQP_parameters()\nparams.use_gpu = true\n\n# Or reduce problem size through preprocessing","category":"section"},{"location":"guide/sparse_matrix_qp/#Slow-Performance","page":"Sparse Matrix QP","title":"Slow Performance","text":"# Check sparsity\nprintln(\"Sparsity: \", nnz(Q) / length(Q) * 100, \"%\")\n\n# If too dense, consider reformulation or different Q operator","category":"section"},{"location":"guide/sparse_matrix_qp/#See-Also","page":"Sparse Matrix QP","title":"See Also","text":"Q Operators Overview - Choosing the right operator\nLASSO Problems - Alternative for least squares\nDirect API - Building models with matrices","category":"section"},{"location":"guide/qap_problems/#QAP-Problems","page":"QAP Problems","title":"QAP Problems","text":"The Quadratic Assignment Problem (QAP) is a fundamental combinatorial optimization problem. HPRQP provides a specialized operator for efficiently solving QAP and its relaxations.","category":"section"},{"location":"guide/qap_problems/#Problem-Formulation","page":"QAP Problems","title":"Problem Formulation","text":"The QAP aims to assign n facilities to n locations to minimize:\n\nmin_pi quad sum_i=1^n sum_j=1^n f_ij cdot d_pi(i)pi(j)\n\nwhere:\n\nf_ij is the flow between facilities i and j (flow matrix F)\nd_kl is the distance between locations k and l (distance matrix D)\npi is a permutation (assignment)","category":"section"},{"location":"guide/qap_problems/#Linearized-Formulation","page":"QAP Problems","title":"Linearized Formulation","text":"Using decision variables x_ik in 0 1 where x_ik = 1 if facility i is assigned to location k:\n\nbeginarrayll\nmin quad  sum_i=1^n sum_j=1^n sum_k=1^n sum_l=1^n f_ij cdot d_kl cdot x_ik cdot x_jl \ntextst quad  sum_k=1^n x_ik = 1 quad forall i \n sum_i=1^n x_ik = 1 quad forall k \n x_ik in 0 1\nendarray\n\nThis is a quadratic program with the quadratic term having Kronecker product structure: Q = F otimes D.","category":"section"},{"location":"guide/qap_problems/#Continuous-Relaxation","page":"QAP Problems","title":"Continuous Relaxation","text":"Replace x_ik in 01 with x_ik in 01 to get a QP that HPRQP can solve:\n\nbeginarrayll\nmin quad  textvec(X)^T (F otimes D) textvec(X) \ntextst quad  X mathbf1 = mathbf1 quad X^T mathbf1 = mathbf1 \n 0 leq X leq 1\nendarray","category":"section"},{"location":"guide/qap_problems/#Why-Use-the-QAP-Operator?","page":"QAP Problems","title":"Why Use the QAP Operator?","text":"The QAP operator exploits the Kronecker product structure Q = F otimes D:\n\nBenefits:\n\n✅ Memory efficient: Stores F and D (2n^2) instead of full Q (n^4 entries)\n✅ Faster computation: Exploits structure in matrix-vector products\n✅ Numerically stable: Avoids explicitly forming huge Kronecker product\n\nMemory comparison for n = 100:\n\nFull Q matrix: n^4 = 100000000 entries (800 MB)\nF and D matrices: 2n^2 = 20000 entries (0.16 MB)","category":"section"},{"location":"guide/qap_problems/#Basic-Usage","page":"QAP Problems","title":"Basic Usage","text":"using HPRQP\nusing SparseArrays\n\n# Problem size\nn = 10  # Facilities/locations\n\n# Flow matrix (traffic between facilities)\nF = rand(n, n)\nF = (F + F') / 2  # Make symmetric\n\n# Distance matrix (distance between locations)\nD = rand(n, n)\nD = (D + D') / 2  # Make symmetric\n\n# Create QAP operator\nQ_qap = QAPOperatorCPU(F, D, n)\n\n# Build QAP constraints\n# Vectorize X: x = vec(X) has length n^2\nn2 = n * n\n\n# Row sum constraints: X*1 = 1\nA_row = sparse(zeros(n, n2))\nfor i in 1:n\n    for k in 1:n\n        A_row[i, (i-1)*n + k] = 1.0\n    end\nend\n\n# Column sum constraints: X'*1 = 1\nA_col = sparse(zeros(n, n2))\nfor k in 1:n\n    for i in 1:n\n        A_col[k, (i-1)*n + k] = 1.0\n    end\nend\n\n# Combine constraints\nA = vcat(A_row, A_col)\nAL = ones(2n)\nAU = ones(2n)\n\n# No linear term\nc = zeros(n2)\n\n# Box constraints: 0 <= x <= 1\nl = zeros(n2)\nu = ones(n2)\n\n# Build and solve\nmodel = build_from_QAbc(Q_qap, A, c, AL, AU, l, u)\n\nparams = HPRQP_parameters()\nparams.use_gpu = true\nparams.stoptol = 1e-4\n\nresult = optimize(model, params)\n\n# Extract solution matrix\nX_vec = result.x\nX = reshape(X_vec, n, n)\n\nprintln(\"QAP relaxation objective: \", result.primal_obj)\nprintln(\"Solution matrix X:\")\ndisplay(X)","category":"section"},{"location":"guide/qap_problems/#Constructing-QAP-Constraints","page":"QAP Problems","title":"Constructing QAP Constraints","text":"","category":"section"},{"location":"guide/qap_problems/#Helper-Function","page":"QAP Problems","title":"Helper Function","text":"using SparseArrays\n\nfunction build_qap_constraints(n::Int)\n    \"\"\"Build constraint matrix for QAP with n facilities/locations\"\"\"\n    n2 = n * n\n    \n    # Row constraints: sum over k of x[i,k] = 1 for each i\n    rows_row = Int[]\n    cols_row = Int[]\n    vals_row = Float64[]\n    \n    for i in 1:n\n        for k in 1:n\n            idx = (i-1)*n + k  # vec(X) index\n            push!(rows_row, i)\n            push!(cols_row, idx)\n            push!(vals_row, 1.0)\n        end\n    end\n    A_row = sparse(rows_row, cols_row, vals_row, n, n2)\n    \n    # Column constraints: sum over i of x[i,k] = 1 for each k\n    rows_col = Int[]\n    cols_col = Int[]\n    vals_col = Float64[]\n    \n    for k in 1:n\n        for i in 1:n\n            idx = (i-1)*n + k\n            push!(rows_col, k)\n            push!(cols_col, idx)\n            push!(vals_col, 1.0)\n        end\n    end\n    A_col = sparse(rows_col, cols_col, vals_col, n, n2)\n    \n    # Combine\n    A = vcat(A_row, A_col)\n    AL = ones(2n)\n    AU = ones(2n)\n    \n    return A, AL, AU\nend\n\n# Use it\nA, AL, AU = build_qap_constraints(n)","category":"section"},{"location":"guide/qap_problems/#Complete-Example:-Facility-Location","page":"QAP Problems","title":"Complete Example: Facility Location","text":"using HPRQP\nusing SparseArrays\nusing LinearAlgebra\n\n# Problem: Assign 5 facilities to 5 locations\nn = 5\n\n# Flow matrix: how much traffic between facilities\n# Example: factories with material flow\nF = [\n    0  10  5   2   1;\n    10  0  8   3   2;\n    5   8  0   6   4;\n    2   3  6   0   7;\n    1   2  4   7   0\n]\nF = Float64.(F)\n\n# Distance matrix: distance between locations\n# Example: geographical distances\nD = [\n    0.0  1.0  2.0  3.0  4.0;\n    1.0  0.0  1.0  2.0  3.0;\n    2.0  1.0  0.0  1.0  2.0;\n    3.0  2.0  1.0  0.0  1.0;\n    4.0  3.0  2.0  1.0  0.0\n]\n\n# Create QAP operator\nQ_qap = QAPOperatorCPU(F, D, n)\n\n# Build constraints\nA, AL, AU = build_qap_constraints(n)\n\n# Solve relaxation\nmodel = build_from_QAbc(Q_qap, A, zeros(n^2), AL, AU, zeros(n^2), ones(n^2))\n\nparams = HPRQP_parameters()\nparams.use_gpu = false  # Small problem\nresult = optimize(model, params)\n\n# Display solution\nX = reshape(result.x, n, n)\nprintln(\"\\nQAP Relaxation Solution:\")\nprintln(\"Objective value: \", result.primal_obj)\nprintln(\"\\nAssignment matrix X:\")\ndisplay(round.(X, digits=3))\n\n# Find near-integer assignments\nprintln(\"\\nNear-integer assignments (> 0.9):\")\nfor i in 1:n, k in 1:n\n    if X[i,k] > 0.9\n        println(\"  Facility $i → Location $k (x = \", round(X[i,k], digits=3), \")\")\n    end\nend","category":"section"},{"location":"guide/qap_problems/#Rounding-to-Integer-Solution","page":"QAP Problems","title":"Rounding to Integer Solution","text":"The continuous relaxation often gives fractional solutions. Common rounding strategies:","category":"section"},{"location":"guide/qap_problems/#Greedy-Rounding","page":"QAP Problems","title":"Greedy Rounding","text":"function greedy_rounding(X::Matrix)\n    n = size(X, 1)\n    assignment = zeros(Int, n)\n    facilities_assigned = Set{Int}()\n    locations_used = Set{Int}()\n    \n    # Flatten and sort by value\n    entries = [(i, k, X[i,k]) for i in 1:n, k in 1:n]\n    sort!(entries, by=x->x[3], rev=true)\n    \n    # Greedily assign\n    for (i, k, val) in entries\n        if !(i in facilities_assigned) && !(k in locations_used)\n            assignment[i] = k\n            push!(facilities_assigned, i)\n            push!(locations_used, k)\n        end\n    end\n    \n    return assignment\nend\n\n# Use it\nX = reshape(result.x, n, n)\nassignment = greedy_rounding(X)\nprintln(\"Greedy assignment: \", assignment)\n\n# Evaluate objective\nobj = sum(F[i,j] * D[assignment[i], assignment[j]] for i in 1:n, j in 1:n)\nprintln(\"Integer objective: \", obj)","category":"section"},{"location":"guide/qap_problems/#Randomized-Rounding","page":"QAP Problems","title":"Randomized Rounding","text":"function randomized_rounding(X::Matrix; n_samples=100)\n    n = size(X, 1)\n    best_obj = Inf\n    best_assignment = nothing\n    \n    for _ in 1:n_samples\n        assignment = zeros(Int, n)\n        locations = collect(1:n)\n        \n        for i in 1:n\n            # Sample location proportional to X[i,:]\n            probs = X[i, locations]\n            probs ./= sum(probs)\n            \n            k_idx = sample(1:length(locations), Weights(probs))\n            k = locations[k_idx]\n            \n            assignment[i] = k\n            deleteat!(locations, k_idx)\n        end\n        \n        # Evaluate\n        obj = sum(F[i,j] * D[assignment[i], assignment[j]] for i in 1:n, j in 1:n)\n        if obj < best_obj\n            best_obj = obj\n            best_assignment = assignment\n        end\n    end\n    \n    return best_assignment, best_obj\nend","category":"section"},{"location":"guide/qap_problems/#Applications","page":"QAP Problems","title":"Applications","text":"","category":"section"},{"location":"guide/qap_problems/#Factory-Layout","page":"QAP Problems","title":"Factory Layout","text":"# Arrange machines to minimize material handling\nn_machines = 8\n\n# Material flow (parts/hour between machines)\nF = rand(0:10, n_machines, n_machines)\nF = (F + F') / 2\nF[diagind(F)] .= 0\n\n# Distance between locations (meters)\nD = rand(1.0:20.0, n_machines, n_machines)\nD = (D + D') / 2\nD[diagind(D)] .= 0\n\nQ_qap = QAPOperatorCPU(F, D, n_machines)\n# ... solve as above","category":"section"},{"location":"guide/qap_problems/#Communication-Network","page":"QAP Problems","title":"Communication Network","text":"# Assign tasks to processors to minimize communication cost\nn_tasks = 12\n\n# Communication volume between tasks (MB)\nF = rand(0:100, n_tasks, n_tasks)\nF = (F + F') / 2\n\n# Network latency between processors (ms)\nD = rand(1.0:10.0, n_tasks, n_tasks)\nD = (D + D') / 2\n\nQ_qap = QAPOperatorCPU(F, D, n_tasks)\n# ... solve","category":"section"},{"location":"guide/qap_problems/#Performance-Tips","page":"QAP Problems","title":"Performance Tips","text":"GPU for Large Problems:\nparams = HPRQP_parameters()\nparams.use_gpu = true  # Essential for n > 20\nWarm-Start from Heuristics:\n# Get initial assignment from greedy heuristic\nx0 = zeros(n^2)\n# ... fill x0 based on heuristic\n\nparams.initial_x = x0\nHierarchical Approach:\n# Solve small problem first, use to warm-start larger\nn_small = 5\nn_large = 10\n\n# Solve small\nQ_small = QAPOperatorCPU(F[1:n_small, 1:n_small], D[1:n_small, 1:n_small], n_small)\n# ... solve\n\n# Extend solution to larger problem\n# Use as warm-start for full problem","category":"section"},{"location":"guide/qap_problems/#See-Also","page":"QAP Problems","title":"See Also","text":"Q Operators Overview - Understanding Q operators\nSparse Matrix QP - Alternative approach\nDirect API - Building models with operators","category":"section"},{"location":"guide/direct_api/#Direct-API-Usage","page":"Direct API","title":"Direct API Usage","text":"The direct API allows you to solve QP problems by passing matrices and vectors directly, without using MPS files or modeling languages.","category":"section"},{"location":"guide/direct_api/#Basic-Example","page":"Direct API","title":"Basic Example","text":"using HPRQP\nusing SparseArrays\n\n# Problem: min 0.5*(2x₁² + x₁x₂ + 2x₂²) - 3x₁ - 5x₂\n#          s.t. x₁ + 2x₂ ≤ 10\n#               3x₁ + x₂ ≤ 12\n#               x₁, x₂ ≥ 0\n\n# Quadratic and linear terms\nQ = sparse([2.0 0.5; 0.5 2.0])\nc = [-3.0, -5.0]\n\n# Convert to standard form: AL ≤ Ax ≤ AU\nA = sparse([-1.0 -2.0; -3.0 -1.0])  # Note the negation\nAL = [-10.0, -12.0]\nAU = [Inf, Inf]\nl = [0.0, 0.0]\nu = [Inf, Inf]\n\n# Step 1: Build the model\nmodel = build_from_QAbc(Q, A, c, AL, AU, l, u)\n\n# Step 2: Set parameters\nparams = HPRQP_parameters()\nparams.use_gpu = false\n\n# Step 3: Optimize\nresult = optimize(model, params)\n\nprintln(\"Status: \", result.status)\nprintln(\"Optimal value: \", result.primal_obj)\nprintln(\"Solution: \", result.x)","category":"section"},{"location":"guide/direct_api/#Standard-Form-Convention","page":"Direct API","title":"Standard Form Convention","text":"HPRQP uses the convention:\n\nbeginarrayll\nmin quad  frac12 langle x Qx rangle + c^T x \ntextst quad  AL leq Ax leq AU \n l leq x leq u\nendarray","category":"section"},{"location":"guide/direct_api/#Converting-Common-Forms","page":"Direct API","title":"Converting Common Forms","text":"Original Constraint Set A row Set AL_i Set AU_i\na^T x leq b a^T -infty b\na^T x geq b a^T b +infty\na^T x = b a^T b b\nL leq a^T x leq U a^T L U","category":"section"},{"location":"guide/direct_api/#Complete-Example-with-All-Constraint-Types","page":"Direct API","title":"Complete Example with All Constraint Types","text":"using HPRQP\nusing SparseArrays\n\n# Problem with mixed constraints:\n# min   0.5*x'*Q*x + x₁ + 2x₂ + 3x₃\n# s.t.  x₁ + x₂ + x₃ = 5      (equality)\n#       x₁ + 2x₂ ≤ 8          (upper bound)\n#       2x₁ + x₃ ≥ 3          (lower bound)\n#       1 ≤ x₂ + x₃ ≤ 6       (two-sided)\n#       0 ≤ x₁ ≤ 5, x₂ ≥ 0, x₃ free\n\n# Quadratic term (identity matrix for simplicity)\nQ = sparse([1.0 0.0 0.0; 0.0 1.0 0.0; 0.0 0.0 1.0])\n\n# Constraint matrix\nA = sparse([\n    1.0  1.0  1.0;   # x₁ + x₂ + x₃ = 5\n    1.0  2.0  0.0;   # x₁ + 2x₂ ≤ 8\n    2.0  0.0  1.0;   # 2x₁ + x₃ ≥ 3\n    0.0  1.0  1.0    # 1 ≤ x₂ + x₃ ≤ 6\n])\n\n# Constraint bounds\nAL = [5.0, -Inf, 3.0, 1.0]\nAU = [5.0, 8.0, Inf, 6.0]\n\n# Objective\nc = [1.0, 2.0, 3.0]\n\n# Variable bounds (free variables: l = -Inf, u = Inf)\nl = [0.0, 0.0, -Inf]\nu = [5.0, Inf, Inf]\n\n# Build and solve\nmodel = build_from_QAbc(Q, A, c, AL, AU, l, u)\n\nparams = HPRQP_parameters()\nparams.use_gpu = false\nparams.verbose = true\n\nresult = optimize(model, params)\n\nprintln(\"\\nResults:\")\nprintln(\"Status: \", result.status)\nprintln(\"Objective: \", result.primal_obj)\nprintln(\"Solution: x = \", result.x)","category":"section"},{"location":"guide/direct_api/#Working-with-Different-Q-Operators","page":"Direct API","title":"Working with Different Q Operators","text":"","category":"section"},{"location":"guide/direct_api/#Sparse-Matrix-Q","page":"Direct API","title":"Sparse Matrix Q","text":"For general sparse quadratic problems:\n\nusing SparseArrays\n\n# Create a sparse positive semidefinite matrix\nn = 100\nH = sprandn(n, n, 0.1)\nQ = H' * H  # Ensure positive semidefinite\n\nmodel = build_from_QAbc(Q, A, c, AL, AU, l, u)","category":"section"},{"location":"guide/direct_api/#LASSO-Operator","page":"Direct API","title":"LASSO Operator","text":"For L1-regularized least squares problems:\n\nusing HPRQP\n\n# LASSO: min 0.5||Ax - b||² + λ||x||₁\nA_data = randn(100, 50)\nb = randn(100)\nλ = 0.1\n\nQ_lasso = LASSOOperatorCPU(A_data, b, λ)\n\n# Build model with LASSO operator\nmodel = build_from_QAbc(Q_lasso, A_constr, c, AL, AU, l, u)\n\nSee LASSO Problems Guide for more details.","category":"section"},{"location":"guide/direct_api/#QAP-Operator","page":"Direct API","title":"QAP Operator","text":"For quadratic assignment problems:\n\n# QAP: min x'Qx where Q has special structure\nQ_qap = QAPOperatorCPU(F, D, n)\n\nmodel = build_from_QAbc(Q_qap, A, c, AL, AU, l, u)\n\nSee QAP Problems Guide for more details.","category":"section"},{"location":"guide/direct_api/#Working-with-Dense-Matrices","page":"Direct API","title":"Working with Dense Matrices","text":"Dense matrices are automatically converted to sparse format:\n\nusing SparseArrays\n\n# Dense matrix (will be converted automatically with a warning)\nQ_dense = [2.0 0.5 0.0;\n           0.5 2.0 0.5;\n           0.0 0.5 2.0]\n\nA_dense = [1.0 2.0 3.0;\n           4.0 5.0 6.0;\n           7.0 8.0 9.0]\n\n# build_from_QAbc will convert them to sparse automatically\nmodel = build_from_QAbc(Q_dense, A_dense, c, AL, AU, l, u)\n\n# Then solve as usual\nparams = HPRQP_parameters()\nresult = optimize(model, params)","category":"section"},{"location":"guide/direct_api/#Warm-Start-with-Initial-Solutions","page":"Direct API","title":"Warm-Start with Initial Solutions","text":"Provide initial primal/dual solutions to warm-start the solver:\n\n# From previous solve or heuristic\nx0 = [1.0, 2.0]\ny0 = [0.5, 0.3]\n\nparams = HPRQP_parameters()\nparams.initial_x = x0\nparams.initial_y = y0  # Optional\n\nmodel = build_from_QAbc(Q, A, c, AL, AU, l, u)\nresult = optimize(model, params)\n\nUseful for solving sequences of related problems or re-solving with different parameters.","category":"section"},{"location":"guide/direct_api/#Auto-Save-Best-Solution","page":"Direct API","title":"Auto-Save Best Solution","text":"Automatically save the best solution found during optimization to HDF5:\n\nparams = HPRQP_parameters()\nparams.auto_save = true\nparams.save_filename = \"my_qp_optimization.h5\"\n\nresult = optimize(model, params)\n\nUseful for long optimizations that might be interrupted or reach time limits.","category":"section"},{"location":"guide/direct_api/#See-Also","page":"Direct API","title":"See Also","text":"Parameters - Complete guide to solver parameters\nOutput & Results - Understanding solver output and results\nQ Operators Overview - Understanding different Q operators\nSparse Matrix QP - Working with sparse matrices","category":"section"},{"location":"guide/input_overview/#Input-Methods-Overview","page":"Overview","title":"Input Methods Overview","text":"HPRQP supports three different ways to specify and solve quadratic programming problems. Choose the method that best fits your workflow.","category":"section"},{"location":"guide/input_overview/#Quick-Comparison","page":"Overview","title":"Quick Comparison","text":"Method Best For Key Advantage When to Use\nJuMP Integration Model building in Julia High-level modeling language Building models programmatically with algebraic syntax\nMPS Files Standard format files Industry compatibility Reading benchmarks or problems from other tools\nDirect API Matrix-based input Full control, no overhead Working with pre-built matrices or custom algorithms","category":"section"},{"location":"guide/input_overview/#Choosing-Your-Input-Method","page":"Overview","title":"Choosing Your Input Method","text":"","category":"section"},{"location":"guide/input_overview/#Use-JuMP-Integration-if-you:","page":"Overview","title":"Use JuMP Integration if you:","text":"✓ Want to build models using algebraic expressions\n✓ Need a high-level, readable problem formulation\n✓ Are familiar with optimization modeling languages (like AMPL, GAMS)\n✓ Want to easily switch between different solvers\n✓ Prefer working with variables, constraints, and objectives directly\n\nExample use case: Building a portfolio optimization model with quadratic risk terms.\n\nusing JuMP, HPRQP\nmodel = Model(HPRQP.Optimizer)\n@variable(model, x[1:n] >= 0)\n@objective(model, Min, sum(x[i]^2 for i in 1:n) + sum(c[i]*x[i] for i in 1:n))\n@constraint(model, sum(x) == 1)\noptimize!(model)\n\n→ See JuMP Integration Guide\n\n","category":"section"},{"location":"guide/input_overview/#Use-MPS-Files-if-you:","page":"Overview","title":"Use MPS Files if you:","text":"✓ Have problems in MPS format from benchmarks (MAROS, CUTEst, etc.)\n✓ Need to read problems generated by other optimization tools\n✓ Want to use standard QP test sets\n✓ Are comparing solver performance on established benchmarks\n✓ Receive problem files from collaborators or other software\n\nExample use case: Solving benchmark QP problems from standard test sets or problems exported from MATLAB/GAMS.\n\nusing HPRQP\nmodel = build_from_mps(\"path/to/qp_problem.mps\")\nparams = HPRQP_parameters()\nresult = optimize(model, params)\n\n→ See MPS Files Guide\n\n","category":"section"},{"location":"guide/input_overview/#Use-Direct-API-if-you:","page":"Overview","title":"Use Direct API if you:","text":"✓ Already have your problem in matrix form\n✓ Need maximum performance (no modeling overhead)\n✓ Are implementing custom algorithms or research code\n✓ Work with problems generated from scientific computing\n✓ Want precise control over the problem formulation and Q operator\n✓ Are integrating HPRQP into existing numerical code\n\nExample use case: Solving QP subproblems in a decomposition algorithm or using specialized Q operators for structured problems.\n\nusing HPRQP, SparseArrays\nQ = sparse([...])  # Your quadratic term\nA = sparse([...])  # Your constraint matrix\nmodel = build_from_QAbc(Q, A, c, AL, AU, l, u)\nparams = HPRQP_parameters()\nresult = optimize(model, params)\n\n→ See Direct API Guide\n\n","category":"section"},{"location":"guide/input_overview/#Can-I-Use-Multiple-Methods?","page":"Overview","title":"Can I Use Multiple Methods?","text":"Yes! You can use different input methods in the same project. For example:\n\nUse JuMP for rapid prototyping, then switch to Direct API for production\nValidate your Direct API implementation against MPS benchmark files\nBuild models in JuMP and export/import via MPS format","category":"section"},{"location":"guide/input_overview/#Understanding-Q-Operators","page":"Overview","title":"Understanding Q Operators","text":"HPRQP supports different representations of the quadratic term Q:\n\nSparse Matrix - For general sparse quadratic problems\nLASSO Operator - For L1-regularized least squares (||Ax - b||² + λ||x||₁)\nQAP Operator - For quadratic assignment problems\nCustom Operators - Define your own matrix-free operators\n\n→ See Q Operators Overview","category":"section"},{"location":"guide/input_overview/#What's-Next?","page":"Overview","title":"What's Next?","text":"Choose your input method using the guide above\nUnderstand Q operators for your problem type\nConfigure solver parameters in the Parameters guide\nUnderstand the results in the Output & Results guide","category":"section"},{"location":"guide/input_overview/#Standard-Form","page":"Overview","title":"Standard Form","text":"Regardless of input method, HPRQP internally solves problems in the standard form:\n\nbeginarrayll\nmin quad  frac12 langle x Qx rangle + langle c x rangle + c_0\ntextst quad  AL leq Ax leq AU \n l leq x leq u\nendarray\n\nJuMP automatically converts your model to this form\nMPS files are parsed into this representation  \nDirect API lets you specify this form directly","category":"section"},{"location":"api/#API-Reference","page":"API Reference","title":"API Reference","text":"Complete API documentation for HPRQP. For detailed guides, see:\n\nParameters Guide - Detailed parameter explanations\nOutput & Results - Understanding solver output","category":"section"},{"location":"api/#Main-Functions","page":"API Reference","title":"Main Functions","text":"","category":"section"},{"location":"api/#Main-Types","page":"API Reference","title":"Main Types","text":"","category":"section"},{"location":"api/#HPRQP_parameters","page":"API Reference","title":"HPRQP_parameters","text":"Solver parameters struct. Create with default values using HPRQP_parameters().\n\nKey Parameters:\n\nstoptol::Float64: Convergence tolerance (default: 1e-6)\nmax_iter::Int: Maximum iterations (default: 1000000)\nuse_gpu::Bool: Enable GPU acceleration (default: true)\nverbose::Bool: Print iteration logs (default: true)\nwarm_up::Bool: Run warmup solve to eliminate JIT overhead (default: false)\ntime_limit::Float64: Maximum solve time in seconds (default: Inf)\n\nSee Parameters Guide for complete list.","category":"section"},{"location":"api/#HPRQP_results","page":"API Reference","title":"HPRQP_results","text":"Solution results struct returned by optimize().\n\nMain Fields:\n\nstatus::String: Solution status (\"OPTIMAL\", \"MAXITER\", \"TIMELIMIT\")\nx::Vector{Float64}: Primal solution vector\ny::Vector{Float64}: Dual solution for constraints\nz::Vector{Float64}: Dual solution for bounds\nprimal_obj::Float64: Primal objective value\ndual_obj::Float64: Dual objective value\niter::Int: Total iterations\ntime::Float64: Solve time in seconds\n\nSee Output & Results Guide for complete list.","category":"section"},{"location":"api/#Q-Operators","page":"API Reference","title":"Q Operators","text":"The following Q operator types are available for specialized problems:\n\nLASSO_Q_operator_cpu: For LASSO (L1-regularized least squares) problems\nQAP_Q_operator_cpu: For quadratic assignment problems\nSparse matrices (SparseMatrixCSC): For general quadratic programming\n\nSee the Q Operators Guide for detailed information.","category":"section"},{"location":"api/#Quick-Reference","page":"API Reference","title":"Quick Reference","text":"","category":"section"},{"location":"api/#Solving-Problems","page":"API Reference","title":"Solving Problems","text":"Direct API (Matrix Form):\n\n# Step 1: Build the model\nmodel = build_from_QAbc(Q, A, c, AL, AU, l, u)\n\n# Step 2: Set parameters\nparams = HPRQP_parameters()\nparams.stoptol = 1e-6\n\n# Step 3: Optimize\nresult = optimize(model, params)\n\nMPS Files:\n\n# Step 1: Build the model from file\nmodel = build_from_mps(\"problem.mps\")\n\n# Step 2: Set parameters\nparams = HPRQP_parameters()\n\n# Step 3: Optimize\nresult = optimize(model, params)\n\nJuMP:\n\nmodel = Model(HPRQP.Optimizer)\n# ... add variables and constraints ...\noptimize!(model)","category":"section"},{"location":"api/#Common-Parameter-Settings","page":"API Reference","title":"Common Parameter Settings","text":"params = HPRQP_parameters()\nparams.stoptol = 1e-6           # Convergence tolerance\nparams.use_gpu = true           # Enable GPU\nparams.verbose = false          # Silent mode\nparams.time_limit = 3600        # Time limit (seconds)\nparams.warm_up = true           # Enable warmup for accurate timing\nparams.initial_x = x0           # Initial primal solution\nparams.initial_y = y0           # Initial dual solution\nparams.auto_save = true         # Auto-save best solution\nparams.save_filename = \"opt.h5\" # HDF5 file for auto-save","category":"section"},{"location":"api/#Accessing-Results","page":"API Reference","title":"Accessing Results","text":"result.status         # \"OPTIMAL\", \"MAX_ITER\", or \"TIME_LIMIT\"\nresult.primal_obj     # Primal objective value\nresult.x              # Primal solution vector\nresult.y              # Dual solution vector (constraints)\nresult.z              # Dual solution vector (bounds)\nresult.iter           # Total iterations\nresult.time           # Solve time (seconds)\nresult.residuals      # Final residual (max of primal, dual, gap)","category":"section"},{"location":"api/#See-Also","page":"API Reference","title":"See Also","text":"User Guide - Comprehensive usage guides\nExamples - Complete working examples\nQ Operators - Understanding Q operators","category":"section"},{"location":"api/#HPRQP.build_from_mps","page":"API Reference","title":"HPRQP.build_from_mps","text":"build_from_mps(filename::String; verbose::Bool=true)\n\nBuild a QP model from an MPS file.\n\nThis function reads a QP problem from an MPS file and returns a CPU-based model that can be solved with optimize() or solve().\n\nArguments\n\nfilename::String: Path to the MPS file\nverbose::Bool: Whether to print progress information (default: true)\n\nReturns\n\nQP_info_cpu: QP model ready to be solved\n\nExample\n\nusing HPRQP\n\nmodel = build_from_mps(\"problem.mps\")\nparams = HPRQP_parameters()\nresult = optimize(model, params)\n\nSee also: build_from_QAbc, build_from_mat, optimize\n\n\n\n\n\n","category":"function"},{"location":"api/#HPRQP.build_from_QAbc","page":"API Reference","title":"HPRQP.build_from_QAbc","text":"build_from_QAbc(Q, c, A, AL, AU, l, u, obj_constant=0.0)\n\nBuild a QP model from matrix form.\n\nThis function creates a QP problem from the standard form:     min  0.5 <x,Qx> + <c,x> + obj_constant     s.t. AL <= Ax <= AU          l <= x <= u\n\nAccepts both sparse and dense matrices for Q and A. Dense matrices will be automatically  converted to sparse format for efficient computation.\n\nArguments\n\nQ::Union{SparseMatrixCSC, Matrix{Float64}}: Quadratic objective matrix (n × n). Can be sparse or dense.\nc::Vector{Float64}: Linear objective coefficients (length n)\nA::Union{SparseMatrixCSC, Matrix{Float64}}: Constraint matrix (m × n). Can be sparse or dense.\nAL::Vector{Float64}: Lower bounds for constraints Ax (length m)\nAU::Vector{Float64}: Upper bounds for constraints Ax (length m)\nl::Vector{Float64}: Lower bounds for variables x (length n)\nu::Vector{Float64}: Upper bounds for variables x (length n)\nobj_constant::Float64: Constant term in objective function (default: 0.0)\n\nReturns\n\nQP_info_cpu: QP model ready to be solved\n\nExample\n\nusing SparseArrays, HPRQP\n\n# Example 1: Sparse matrices\nQ = sparse([2.0 0.0; 0.0 2.0])\nc = [-3.0, -5.0]\nA = sparse([-1.0 -2.0; -3.0 -1.0])\nAL = [-10.0, -12.0]\nAU = [Inf, Inf]\nl = [0.0, 0.0]\nu = [Inf, Inf]\n\nmodel = build_from_QAbc(Q, c, A, AL, AU, l, u)\nparams = HPRQP_parameters()\nresult = optimize(model, params)\n\n# Example 2: Dense matrices (automatically converted)\nn = 10\nQ = zeros(n, n)  # Empty or dense Q matrix\nQ[1,1] = 2.0\nc = ones(n)\nA = ones(5, n)  # Dense constraint matrix\nAL = -Inf * ones(5)\nAU = ones(5)\nl = zeros(n)\nu = ones(n)\nmodel = build_from_QAbc(Q, c, A, AL, AU, l, u)\n\nSee also: build_from_mps, build_from_mat, optimize\n\n\n\n\n\n","category":"function"},{"location":"api/#HPRQP.build_from_mat","page":"API Reference","title":"HPRQP.build_from_mat","text":"build_from_mat(filename::String; problem_type::String=\"QAP\", lambda::Float64=1.0, verbose::Bool=true)\n\nBuild a QP model from a MAT file (for QAP or LASSO problems).\n\nThis function reads a QAP (Quadratic Assignment Problem) or LASSO problem from a .mat file. Note: This function stores metadata that will be used to create operator-based models during solve().\n\nArguments\n\nfilename::String: Path to the MAT file\nproblem_type::String: Type of problem - \"QAP\" or \"LASSO\" (default: \"QAP\")\nlambda::Float64: Regularization parameter for LASSO (default: 1.0)\nverbose::Bool: Whether to print progress information (default: true)\n\nReturns\n\nTuple: (metadatadict, problemtype) containing problem data\n\nExample\n\nusing HPRQP\n\nmodel_info, prob_type = build_from_mat(\"qap_problem.mat\", problem_type=\"QAP\")\nparams = HPRQP_parameters()\nparams.problem_type = prob_type\nresult = optimize((model_info, prob_type), params)\n\nSee also: build_from_mps, build_from_QAbc, optimize\n\n\n\n\n\n","category":"function"},{"location":"api/#HPRQP.build_from_ABST","page":"API Reference","title":"HPRQP.build_from_ABST","text":"build_from_ABST(A, B, S, T; verbose::Bool=true)\n\nBuild a QP model for Quadratic Assignment Problem (QAP) from matrices A, B, S, T.\n\nThis function creates a QAP problem in the standard form used by HPR-QP:     min  <vec(X), Qvec(X)>     s.t. Xe = e, X'*e = e  (doubly stochastic constraints)          X >= 0\n\nWhere Q(X) = 2(AXB - SX - X*T) is represented as a matrix-free operator using the CUSTOMQOPERATOR API.\n\nArguments\n\nA::Matrix{Float64}: Distance matrix for facility locations (n × n)\nB::Matrix{Float64}: Flow matrix between facilities (n × n)\nS::Matrix{Float64}: Linear term for rows (n × n)\nT::Matrix{Float64}: Linear term for columns (n × n)\nverbose::Bool: Whether to print progress information (default: true)\n\nReturns\n\nQP_info_cpu: QP model ready to be solved with operator-based Q\n\nExample\n\nusing HPRQP\n\n# Define QAP data matrices\nn = 10\nA = rand(n, n)\nB = rand(n, n)\nS = zeros(n, n)\nT = zeros(n, n)\n\nmodel = build_from_ABST(A, B, S, T)\nparams = HPRQP_parameters()\nresult = optimize(model, params)\n\nSee also: build_from_Ab_lambda, build_from_mat, build_from_QAbc, optimize\n\n\n\n\n\n","category":"function"},{"location":"api/#HPRQP.build_from_Ab_lambda","page":"API Reference","title":"HPRQP.build_from_Ab_lambda","text":"build_from_Ab_lambda(A, b, lambda; verbose::Bool=true)\n\nBuild a QP model for LASSO regression from data matrix A, target vector b, and regularization λ.\n\nThis function creates a LASSO problem in the standard form:     min  0.5 ||A*x - b||₂² + λ ||x||₁\n\nWhich is reformulated as a QP with operator-based Q:     min  0.5 <x, Q*x> + <c, x> + constant     s.t. (no constraints on x, handled via proximal operator for L1)\n\nWhere Q = A'*A is represented as a matrix-free operator using the CUSTOMQOPERATOR API.\n\nArguments\n\nA::SparseMatrixCSC{Float64}: Data matrix (m × n)\nb::Vector{Float64}: Target vector (length m)\nlambda::Float64: Regularization parameter (must be positive)\nverbose::Bool: Whether to print progress information (default: true)\n\nReturns\n\nQP_info_cpu: QP model ready to be solved with operator-based Q\n\nExample\n\nusing HPRQP, SparseArrays\n\n# Define LASSO data\nm, n = 100, 50\nA = sprandn(m, n, 0.1)\nb = randn(m)\nlambda = 0.01 * norm(A' * b, Inf)\n\nmodel = build_from_Ab_lambda(A, b, lambda)\nparams = HPRQP_parameters()\nresult = optimize(model, params)\n\nSee also: build_from_ABST, build_from_mat, build_from_QAbc, optimize\n\n\n\n\n\n","category":"function"},{"location":"api/#HPRQP.optimize","page":"API Reference","title":"HPRQP.optimize","text":"optimize(model::QP_info_cpu, params::HPRQP_parameters)\n\nSolve a QP model with optional warm-up phase.\n\nThis is the main entry point for solving QP problems. It handles:\n\nOptional warm-up phase to avoid JIT compilation overhead\nCalls solve() which does scaling, GPU transfer, and optimization\n\nArguments\n\nmodel::QP_info_cpu: QP model built from buildfrommps(), buildfromQAbc(), etc.\nparams::HPRQP_parameters: Solver parameters\n\nReturns\n\nHPRQP_results: Solution results\n\nExample\n\nusing HPRQP\n\nmodel = build_from_mps(\"problem.mps\")\nparams = HPRQP_parameters()\nparams.stoptol = 1e-8\nparams.warm_up = true\nresult = optimize(model, params)\n\nSee also: build_from_mps, build_from_QAbc\n\n\n\n\n\n","category":"function"},{"location":"api/#HPRQP.Optimizer","page":"API Reference","title":"HPRQP.Optimizer","text":"Optimizer()\n\nCreate a new HPRQP Optimizer object.\n\nSet optimizer attributes using MOI.RawOptimizerAttribute or JuMP.set_optimizer_attribute.\n\nExample\n\nusing JuMP, HPRQP\nmodel = JuMP.Model(HPRQP.Optimizer)\nset_optimizer_attribute(model, \"stoptol\", 1e-6)\nset_optimizer_attribute(model, \"use_gpu\", true)\nset_optimizer_attribute(model, \"device_number\", 0)\n\n\n\n\n\n","category":"type"},{"location":"guide/parameters/#Solver-Parameters","page":"Parameters","title":"Solver Parameters","text":"HPRQP provides extensive customization through the HPRQP_parameters type. This guide explains all available parameters and their effects on solver behavior.","category":"section"},{"location":"guide/parameters/#Parameter-Summary-Table","page":"Parameters","title":"Parameter Summary Table","text":"Parameter Default Value Description\nstoptol 1e-6 Stopping tolerance for convergence checks.\nsigma -1 (auto) Initial value of the σ parameter used in the algorithm.\nmax_iter typemax(Int32) Maximum number of iterations allowed.\nsigma_fixed false Whether σ is fixed throughout the optimization process.\ntime_limit 3600.0 Maximum allowed runtime (seconds) for the algorithm.\neig_factor 1.05 Factor used to scale the maximum eigenvalue estimation.\ncheck_iter 100 Frequency (in iterations) to check for convergence or perform other checks.\nwarm_up false Determines if a warm-up phase is performed before main execution.\nspmv_mode_Q \"auto\" Mode for Q matrix-vector multiplication (e.g., \"auto\", \"CUSPARSE\", \"customized\", \"operator\").\nspmv_mode_A \"auto\" Mode for A matrix-vector multiplication (e.g., \"auto\", \"CUSPARSE\", \"customized\").\nprint_frequency -1 (auto) Frequency (in iterations) for printing progress or logging information.\ndevice_number 0 GPU device number (e.g., 0, 1, 2, 3).\nuse_Ruiz_scaling true Whether to apply Ruiz scaling to the problem data.\nuse_bc_scaling false Whether to apply bc scaling. (For QAP and LASSO, only this scaling is applicable)\nuse_l2_scaling false Whether to apply L2-norm based scaling.\nuse_Pock_Chambolle_scaling true Whether to apply Pock-Chambolle scaling to the problem data.\nproblem_type \"QP\" Type of problem being solved (e.g., \"QP\", \"LASSO\", \"QAP\").\nlambda 0.0 Regularization parameter for LASSO problems.\ninitial_x nothing Initial primal solution for warm-start.\ninitial_y nothing Initial dual solution for warm-start.\nauto_save false Automatically save best x, y, z, w, and sigma during optimization.\nsave_filename \"hprqp_autosave.h5\" Filename for auto-save HDF5 file.\nverbose true Enable verbose output during optimization.\nuse_gpu true Whether to use GPU acceleration (requires CUDA).","category":"section"},{"location":"guide/parameters/#Creating-Parameters","page":"Parameters","title":"Creating Parameters","text":"using HPRQP\n\n# Create with default values\nparams = HPRQP_parameters()\n\n# Customize as needed\nparams.stoptol = 1e-6\nparams.use_gpu = true\nparams.verbose = true\nparams.time_limit = 1800.0","category":"section"},{"location":"guide/parameters/#Parameter-Details","page":"Parameters","title":"Parameter Details","text":"","category":"section"},{"location":"guide/parameters/#Convergence-Control","page":"Parameters","title":"Convergence Control","text":"stoptol: Stopping tolerance for convergence checks. Lower values require higher accuracy but may take longer.\nparams.stoptol = 1e-9  # High accuracy\nparams.stoptol = 1e-4  # Faster, less accurate\nmax_iter: Maximum number of iterations. Set lower to prevent excessive computation time.\nparams.max_iter = 100000\ntime_limit: Maximum runtime in seconds before the solver stops.\nparams.time_limit = 3600.0  # 1 hour\ncheck_iter: How often (in iterations) to check convergence and update statistics.\nparams.check_iter = 100","category":"section"},{"location":"guide/parameters/#Algorithm-Parameters","page":"Parameters","title":"Algorithm Parameters","text":"sigma: Initial value of the σ parameter. When set to -1, it's automatically computed.\nparams.sigma = -1  # Auto-compute (recommended)\nparams.sigma = 0.5 # Manual value\nsigma_fixed: Whether σ remains constant or adapts during optimization.\nparams.sigma_fixed = false  # Adaptive (default)\nparams.sigma_fixed = true   # Fixed\neig_factor: Scaling factor for maximum eigenvalue estimation.\nparams.eig_factor = 1.05","category":"section"},{"location":"guide/parameters/#Matrix-Vector-Multiplication-Modes","page":"Parameters","title":"Matrix-Vector Multiplication Modes","text":"spmv_mode_Q: Controls how Q matrix-vector products are computed.\n\"auto\": Automatically select best method\n\"CUSPARSE\": Use CUDA sparse matrix operations\n\"customized\": Use custom kernels\n\"operator\": Use operator interface (for LASSO/QAP)\nspmv_mode_A: Controls how A matrix-vector products are computed.\n\"auto\": Automatically select best method\n\"CUSPARSE\": Use CUDA sparse matrix operations\n\"customized\": Use custom kernels","category":"section"},{"location":"guide/parameters/#Scaling-Options","page":"Parameters","title":"Scaling Options","text":"Scaling improves numerical stability and convergence:\n\nuse_Ruiz_scaling: Apply Ruiz equilibration to balance matrix rows/columns.\nparams.use_Ruiz_scaling = true\nuse_bc_scaling: Scale the objective vector (c) and constraint bounds (b). Required for QAP and LASSO problems.\nparams.use_bc_scaling = false  # Default for standard QP\nparams.use_bc_scaling = true   # Required for QAP/LASSO\nuse_l2_scaling: Apply L2-norm based scaling.\nparams.use_l2_scaling = false\nuse_Pock_Chambolle_scaling: Apply Pock-Chambolle diagonal scaling.\nparams.use_Pock_Chambolle_scaling = true","category":"section"},{"location":"guide/parameters/#GPU-Configuration","page":"Parameters","title":"GPU Configuration","text":"use_gpu: Enable GPU acceleration (requires CUDA).\nparams.use_gpu = true   # Use GPU (faster for large problems)\nparams.use_gpu = false  # CPU only\ndevice_number: Select which GPU to use (0-indexed).\nparams.device_number = 0  # First GPU\nparams.device_number = 1  # Second GPU\nwarm_up: Perform warm-up to ensure accurate timing (accounts for JIT compilation).\nparams.warm_up = false  # Default\nparams.warm_up = true   # For benchmarking","category":"section"},{"location":"guide/parameters/#Output-Control","page":"Parameters","title":"Output Control","text":"verbose: Enable detailed solver output.\nparams.verbose = true   # Show progress\nparams.verbose = false  # Silent\nprint_frequency: How often to print iteration information. -1 means automatic.\nparams.print_frequency = -1   # Auto\nparams.print_frequency = 100  # Every 100 iterations","category":"section"},{"location":"guide/parameters/#Warm-Start","page":"Parameters","title":"Warm-Start","text":"initial_x: Initial primal solution vector.\nparams.initial_x = x0  # From previous solve\ninitial_y: Initial dual solution vector.\nparams.initial_y = y0  # From previous solve","category":"section"},{"location":"guide/parameters/#Auto-Save-Feature","page":"Parameters","title":"Auto-Save Feature","text":"auto_save: Automatically save the best solution during optimization.\nparams.auto_save = true\nsave_filename: HDF5 filename for auto-saved solutions.\nparams.save_filename = \"my_problem_autosave.h5\"","category":"section"},{"location":"guide/parameters/#Problem-Type","page":"Parameters","title":"Problem Type","text":"problem_type: Specifies the type of problem being solved.\n\"QP\": Standard quadratic programming\n\"LASSO\": LASSO regression problems\n\"QAP\": Quadratic assignment problems\nlambda: Regularization parameter for LASSO problems.\nparams.problem_type = \"LASSO\"\nparams.lambda = 0.1","category":"section"},{"location":"guide/parameters/#Common-Configurations","page":"Parameters","title":"Common Configurations","text":"","category":"section"},{"location":"guide/parameters/#High-Accuracy","page":"Parameters","title":"High Accuracy","text":"params = HPRQP_parameters()\nparams.stoptol = 1e-9\nparams.time_limit = 7200.0\nparams.max_iter = 500000","category":"section"},{"location":"guide/parameters/#Fast-Approximate-Solutions","page":"Parameters","title":"Fast Approximate Solutions","text":"params = HPRQP_parameters()\nparams.stoptol = 1e-4\nparams.time_limit = 300.0\nparams.check_iter = 200","category":"section"},{"location":"guide/parameters/#CPU-Only-(No-GPU-Available)","page":"Parameters","title":"CPU-Only (No GPU Available)","text":"params = HPRQP_parameters()\nparams.use_gpu = false\nparams.verbose = true","category":"section"},{"location":"guide/parameters/#LASSO-Problems","page":"Parameters","title":"LASSO Problems","text":"params = HPRQP_parameters()\nparams.problem_type = \"LASSO\"\nparams.lambda = 0.1\nparams.use_bc_scaling = true  # Required for LASSO\nparams.spmv_mode_Q = \"operator\"","category":"section"},{"location":"guide/parameters/#QAP-Problems","page":"Parameters","title":"QAP Problems","text":"params = HPRQP_parameters()\nparams.problem_type = \"QAP\"\nparams.use_bc_scaling = true  # Required for QAP\nparams.spmv_mode_Q = \"operator\"","category":"section"},{"location":"guide/parameters/#With-Auto-Save-and-Warm-Start","page":"Parameters","title":"With Auto-Save and Warm-Start","text":"params = HPRQP_parameters()\nparams.auto_save = true\nparams.save_filename = \"my_solution.h5\"\nparams.initial_x = x0\nparams.initial_y = y0","category":"section"},{"location":"guide/parameters/#Silent/Batch-Processing","page":"Parameters","title":"Silent/Batch Processing","text":"params = HPRQP_parameters()\nparams.verbose = false\nparams.warm_up = false","category":"section"},{"location":"guide/parameters/#Debugging/Analysis","page":"Parameters","title":"Debugging/Analysis","text":"params = HPRQP_parameters()\nparams.verbose = true\nparams.print_frequency = 10\nparams.check_iter = 10\nparams.max_iter = 1000","category":"section"},{"location":"guide/q_operators_overview/#Q-Operators-Overview","page":"Overview","title":"Q Operators Overview","text":"HPRQP supports different representations of the quadratic term Q in the objective function. This flexibility allows you to leverage problem structure for improved performance and memory efficiency.","category":"section"},{"location":"guide/q_operators_overview/#What-is-a-Q-Operator?","page":"Overview","title":"What is a Q Operator?","text":"In the quadratic programming problem:\n\nmin quad frac12 langle x Qx rangle + langle c x rangle\n\nthe quadratic term frac12 langle x Qx rangle is represented by a Q operator. Instead of always storing Q as an explicit matrix, HPRQP allows you to define how to compute Qx for any vector x.","category":"section"},{"location":"guide/q_operators_overview/#Available-Q-Operators","page":"Overview","title":"Available Q Operators","text":"HPRQP provides three built-in Q operators plus support for custom operators:\n\nOperator Best For Memory Speed\nSparse Matrix General QP problems O(nnz) Fast\nLASSO L1-regularized least squares O(mn) Very Fast\nQAP Quadratic assignment problems O(n^2) Fast\nCustom Specialized structures User-defined User-defined","category":"section"},{"location":"guide/q_operators_overview/#Sparse-Matrix-Operator","page":"Overview","title":"Sparse Matrix Operator","text":"Use when: You have a general sparse quadratic objective.\n\nusing HPRQP\nusing SparseArrays\n\n# Define Q as a sparse matrix\nQ = sparse([2.0 0.5 0.0; 0.5 2.0 0.5; 0.0 0.5 2.0])\n\n# Build model (automatically uses SparseMatrixQOperator)\nmodel = build_from_QAbc(Q, A, c, AL, AU, l, u)\n\nCharacteristics:\n\nGeneral-purpose operator for any sparse positive semidefinite matrix\nMemory: O(textnnz(Q)) where nnz is number of non-zeros\nComputation: Sparse matrix-vector product\nAutomatically selected when you pass a sparse matrix\n\n→ Full Guide: Sparse Matrix QP\n\n","category":"section"},{"location":"guide/q_operators_overview/#LASSO-Operator","page":"Overview","title":"LASSO Operator","text":"Use when: Solving L1-regularized least squares problems.\n\nmin quad frac12 Ax - b^2 + lambda x_1\n\nusing HPRQP\n\n# Problem data\nA = randn(100, 50)  # Design matrix\nb = randn(100)      # Observations\nλ = 0.1             # Regularization parameter\n\n# Create LASSO operator (Q = A'A implicitly)\nQ_lasso = LASSOOperatorCPU(A, b, λ)\n\n# Build model\nmodel = build_from_QAbc(Q_lasso, A_constr, c, AL, AU, l, u)\n\nCharacteristics:\n\nSpecialized for regression with L1 penalty\nMemory: Stores A and b, not A'A\nComputation: Two matrix-vector products instead of one\nMore efficient than forming A'A explicitly\n\n→ Full Guide: LASSO Problems\n\n","category":"section"},{"location":"guide/q_operators_overview/#QAP-Operator","page":"Overview","title":"QAP Operator","text":"Use when: Solving quadratic assignment problems or similar structured QPs.\n\nusing HPRQP\n\n# QAP data: Flow and distance matrices\nF = rand(n, n)  # Flow between facilities\nD = rand(n, n)  # Distance between locations\n\n# Create QAP operator\nQ_qap = QAPOperatorCPU(F, D, n)\n\n# Build model\nmodel = build_from_QAbc(Q_qap, A, c, AL, AU, l, u)\n\nCharacteristics:\n\nSpecialized for quadratic assignment structure\nMemory: Stores F and D matrices\nComputation: Exploits Kronecker product structure\nEfficient for large-scale QAP relaxations\n\n→ Full Guide: QAP Problems\n\n","category":"section"},{"location":"guide/q_operators_overview/#Custom-Q-Operators","page":"Overview","title":"Custom Q Operators","text":"You can define your own Q operators for specialized problem structures.\n\nWhen to use:\n\nYour problem has special structure not covered by built-in operators\nYou want matrix-free implementations\nYou need to integrate with external libraries\n\nExample: Diagonal plus low-rank structure\n\n# Define your operator type\nstruct DiagonalPlusLowRankCPU <: AbstractQOperatorCPU\n    diag::Vector{Float64}\n    U::Matrix{Float64}  # n × k matrix\nend\n\n# Implement the interface (see custom operator guide)\nfunction to_gpu(Q::DiagonalPlusLowRankCPU)\n    # Transfer to GPU...\nend\n\nfunction Qmap!(x, Qx, Q::DiagonalPlusLowRankGPU)\n    # Compute Qx = (Diag + UU')x\n    # Qx = diag .* x + U * (U' * x)\nend\n\nSee src/Q_operators/Q_operator_interface.jl for the complete interface specification.\n\n","category":"section"},{"location":"guide/q_operators_overview/#Choosing-the-Right-Operator","page":"Overview","title":"Choosing the Right Operator","text":"","category":"section"},{"location":"guide/q_operators_overview/#Decision-Tree","page":"Overview","title":"Decision Tree","text":"Do you have a least squares problem with L1 regularization?\n├─ YES → Use LASSOOperator\n└─ NO\n    ├─ Is your problem a QAP or similar Kronecker structure?\n    │   ├─ YES → Use QAPOperator\n    │   └─ NO\n    │       ├─ Do you have a general sparse matrix?\n    │       │   ├─ YES → Use SparseMatrixOperator (default)\n    │       │   └─ NO\n    │       │       └─ Define CustomOperator for your structure","category":"section"},{"location":"guide/q_operators_overview/#Performance-Comparison","page":"Overview","title":"Performance Comparison","text":"For a problem with n=10,000 variables:\n\nOperator Memory (GB) Time/Iteration (ms) Notes\nSparse (1% density) 0.8 5 General purpose\nLASSO (m=5000) 0.4 8 Avoids forming A'A\nQAP 1.6 12 Exploits structure\nDense 800 1000 Impractical\n\nTimings are approximate and depend on hardware","category":"section"},{"location":"guide/q_operators_overview/#Operator-Interface","page":"Overview","title":"Operator Interface","text":"All Q operators must implement:\n\n# CPU version\nstruct MyQOperatorCPU <: AbstractQOperatorCPU\n    # Your data fields\nend\n\n# GPU version  \nmutable struct MyQOperatorGPU <: AbstractQOperator\n    # GPU data fields\n    temp::CuVector{Float64}  # Temporary storage\nend\n\n# Required methods:\nto_gpu(Q::MyQOperatorCPU) -> MyQOperatorGPU\nQmap!(x::CuVector, Qx::CuVector, Q::MyQOperatorGPU) -> nothing\nget_temp_size(Q::MyQOperatorCPU) -> Int\nget_operator_name(::Type{MyQOperatorGPU}) -> String\nget_problem_size(Q::MyQOperatorCPU) -> Int","category":"section"},{"location":"guide/q_operators_overview/#Examples","page":"Overview","title":"Examples","text":"","category":"section"},{"location":"guide/q_operators_overview/#Comparing-Operators","page":"Overview","title":"Comparing Operators","text":"using HPRQP\nusing SparseArrays\nusing BenchmarkTools\n\n# Same problem, different representations\nA = randn(100, 50)\nb = randn(50)\n\n# Method 1: Form Q = A'A explicitly\nQ_explicit = sparse(A' * A)\nmodel1 = build_from_QAbc(Q_explicit, ...)\n\n# Method 2: Use LASSO operator  \nQ_lasso = LASSOOperatorCPU(A, b, 0.0)\nmodel2 = build_from_QAbc(Q_lasso, ...)\n\n# Compare\n@btime optimize(model1, params)  # Sparse matrix\n@btime optimize(model2, params)  # LASSO operator","category":"section"},{"location":"guide/q_operators_overview/#See-Also","page":"Overview","title":"See Also","text":"Sparse Matrix QP - Using sparse matrices\nLASSO Problems - L1-regularized least squares\nQAP Problems - Quadratic assignment problems\nDirect API - Building models with Q operators","category":"section"},{"location":"guide/mps_files/#Solving-MPS-Files","page":"MPS Files","title":"Solving MPS Files","text":"HPRQP can directly read and solve quadratic programming problems in MPS (Mathematical Programming System) format, a widely-used industry standard format.","category":"section"},{"location":"guide/mps_files/#Quick-Start","page":"MPS Files","title":"Quick Start","text":"using HPRQP\n\n# Step 1: Build model from MPS file\nmodel = build_from_mps(\"path/to/qp_problem.mps\")\n\n# Step 2: Configure solver parameters\nparams = HPRQP_parameters()\nparams.stoptol = 1e-4\n\n# Step 3: Optimize\nresult = optimize(model, params)","category":"section"},{"location":"guide/mps_files/#Working-with-MPS-Files","page":"MPS Files","title":"Working with MPS Files","text":"","category":"section"},{"location":"guide/mps_files/#Basic-Usage","page":"MPS Files","title":"Basic Usage","text":"using HPRQP\n\n# Build the model\nmodel = build_from_mps(\"qp_model.mps\")\n\n# Set up parameters\nparams = HPRQP_parameters()\n\n# Solve\nresult = optimize(model, params)\n\nif result.status == \"OPTIMAL\"\n    println(\"Found optimal solution!\")\n    println(\"Objective: \", result.primal_obj)\n    println(\"Solution vector: \", result.x)\nelse\n    println(\"Solver stopped with status: \", result.status)\nend","category":"section"},{"location":"guide/mps_files/#With-Custom-Parameters","page":"MPS Files","title":"With Custom Parameters","text":"# Build model\nmodel = build_from_mps(\"large_qp_problem.mps\")\n\n# Configure parameters\nparams = HPRQP_parameters()\nparams.stoptol = 1e-9          # Higher accuracy\nparams.time_limit = 3600       # 1 hour time limit\nparams.use_gpu = true          # Enable GPU\nparams.verbose = true          # Show progress\nparams.warm_up = true          # Enable warmup for accurate timing\n\n# Solve\nresult = optimize(model, params)\n\ntip: Parameter Reference\nFor detailed explanations of all parameters, see the Parameters guide.","category":"section"},{"location":"guide/mps_files/#MPS-Format-for-QP-Problems","page":"MPS Files","title":"MPS Format for QP Problems","text":"MPS files can encode quadratic programming problems using the QUADOBJ section:\n\nNAME          EXAMPLE_QP\nROWS\n N  OBJ\n L  CON1\n L  CON2\nCOLUMNS\n    X1        OBJ       -3.0\n    X1        CON1       1.0\n    X1        CON2       3.0\n    X2        OBJ       -5.0\n    X2        CON1       2.0\n    X2        CON2       1.0\nRHS\n    RHS1      CON1      10.0\n    RHS1      CON2      12.0\nBOUNDS\n LO BND1      X1         0.0\n LO BND1      X2         0.0\nQUADOBJ\n    X1        X1         2.0\n    X1        X2         0.5\n    X2        X2         2.0\nENDATA\n\nThe QUADOBJ section defines the Q matrix where each entry specifies a quadratic term.","category":"section"},{"location":"guide/mps_files/#Common-QP-Sources","page":"MPS Files","title":"Common QP Sources","text":"","category":"section"},{"location":"guide/mps_files/#MAROS-and-MESZAROS","page":"MPS Files","title":"MAROS and MESZAROS","text":"QP test set from Maros and Meszaros:\n\nContains various QP problems\nAvailable online from QP benchmarking repositories\nStandard benchmark for QP solvers","category":"section"},{"location":"guide/mps_files/#CUTEst","page":"MPS Files","title":"CUTEst","text":"Constrained and Unconstrained Testing Environment:\n\nDownload from: https://github.com/JuliaSmoothOptimizers/CUTEst.jl\nContains QP and general nonlinear problems\nCan export to MPS format","category":"section"},{"location":"guide/mps_files/#Custom-QP-Problems","page":"MPS Files","title":"Custom QP Problems","text":"Generate your own MPS files from Julia:\n\nusing JuMP\n\n# Build a QP model\nmodel = Model()\n@variable(model, x[1:n])\n@objective(model, Min, 0.5*sum(Q[i,j]*x[i]*x[j] for i in 1:n, j in 1:n) + sum(c[i]*x[i] for i in 1:n))\n# ... add constraints ...\n\n# Export to MPS\nwrite_to_file(model, \"my_qp.mps\")","category":"section"},{"location":"guide/mps_files/#Performance-Tips","page":"MPS Files","title":"Performance Tips","text":"GPU vs CPU: \nUse GPU for large problems (> 10,000 variables/constraints)\nUse CPU for small to medium problems or when GPU is unavailable\nTolerance:\nUse 1e-6 or 1e-8 for high-accuracy requirements\nDefault 1e-4 is suitable for most applications\nTime Limits:\nSet reasonable time limits for batch processing\nDefault is 3600 seconds (1 hour)\nScaling:\nKeep scaling enabled for better numerical stability\nDisable only if you have pre-scaled data\nQ Operator:\nFor problems with special structure (LASSO, QAP), consider using specialized operators\nSparse matrix operator is used by default for MPS files","category":"section"},{"location":"guide/mps_files/#Troubleshooting","page":"MPS Files","title":"Troubleshooting","text":"","category":"section"},{"location":"guide/mps_files/#File-Not-Found","page":"MPS Files","title":"File Not Found","text":"# Use absolute path or check current directory\nusing Pkg\npwd()  # Check current directory\n\nmodel = build_from_mps(\"/full/path/to/problem.mps\")","category":"section"},{"location":"guide/mps_files/#Parsing-Errors","page":"MPS Files","title":"Parsing Errors","text":"If MPS file has format issues:\n\nEnsure QUADOBJ section is properly formatted\nCheck that all variable names are consistent\nVerify bounds are correctly specified","category":"section"},{"location":"guide/mps_files/#Memory-Issues","page":"MPS Files","title":"Memory Issues","text":"For very large MPS files:\n\nparams = HPRQP_parameters()\nparams.use_gpu = true  # Offload to GPU memory","category":"section"},{"location":"guide/mps_files/#See-Also","page":"MPS Files","title":"See Also","text":"Parameters - Complete guide to solver parameters and configuration\nOutput & Results - Understanding and interpreting solver results\nDirect API - Alternative matrix-based input method","category":"section"},{"location":"guide/lasso_problems/#LASSO-Problems","page":"LASSO Problems","title":"LASSO Problems","text":"The LASSO (Least Absolute Shrinkage and Selection Operator) is a regression method that performs both variable selection and regularization. HPRQP provides a specialized operator for efficiently solving LASSO problems.","category":"section"},{"location":"guide/lasso_problems/#Problem-Formulation","page":"LASSO Problems","title":"Problem Formulation","text":"The LASSO problem is:\n\nmin_x quad frac12 Ax - b^2 + lambda x_1\n\nwhere:\n\nA in mathbbR^m times n is the design matrix (features)\nb in mathbbR^m is the response vector\nx in mathbbR^n is the coefficient vector to solve for\nlambda  0 is the regularization parameter\n\nThis is equivalent to the QP:\n\nmin_x quad frac12 x^T (A^T A) x - (A^T b)^T x + lambda x_1","category":"section"},{"location":"guide/lasso_problems/#Why-Use-the-LASSO-Operator?","page":"LASSO Problems","title":"Why Use the LASSO Operator?","text":"Instead of explicitly forming Q = A^T A:\n\nBenefits:\n\n✅ Memory efficient: Stores A instead of A^T A\n✅ Numerically stable: Avoids conditioning issues from forming A^T A\n✅ Faster: Two matrix-vector products A^T(Ax) instead of one with A^T A\n\nWhen m = 1000 n = 500:\n\nSparse matrix operator: stores A^T A (potentially n^2 = 250000 entries)\nLASSO operator: stores A (only mn = 500000 entries, but structured)","category":"section"},{"location":"guide/lasso_problems/#Basic-Usage","page":"LASSO Problems","title":"Basic Usage","text":"using HPRQP\n\n# Problem data\nm, n = 100, 50\nA = randn(m, n)  # Design matrix\nb = randn(m)     # Observations\nλ = 0.1          # Regularization parameter\n\n# Create LASSO operator\nQ_lasso = LASSOOperatorCPU(A, b, λ)\n\n# No additional constraints (or add your own)\nA_constr = sparse(zeros(0, n))\nAL = Float64[]\nAU = Float64[]\nc = zeros(n)  # Linear term is handled by LASSO operator\nl = fill(-Inf, n)\nu = fill(Inf, n)\n\n# Build and solve\nmodel = build_from_QAbc(Q_lasso, A_constr, c, AL, AU, l, u)\n\nparams = HPRQP_parameters()\nparams.use_gpu = true\nresult = optimize(model, params)\n\n# Analyze sparsity\nsparsity = sum(abs.(result.x) .> 1e-6)\nprintln(\"Non-zero coefficients: \", sparsity, \" / \", n)\nprintln(\"Sparsity: \", (1 - sparsity/n) * 100, \"%\")","category":"section"},{"location":"guide/lasso_problems/#Complete-Example-with-Constraints","page":"LASSO Problems","title":"Complete Example with Constraints","text":"using HPRQP\nusing SparseArrays\n\n# Generate synthetic data\nm, n = 200, 100\nA = randn(m, n)\nx_true = sparsevec([1, 5, 10, 25, 50], randn(5), n)  # Sparse truth\nnoise = 0.1 * randn(m)\nb = A * x_true + noise\n\nλ = 0.5  # Regularization\n\n# Create LASSO operator\nQ_lasso = LASSOOperatorCPU(A, b, λ)\n\n# Add non-negativity constraint\nA_constr = sparse(zeros(0, n))\nAL = Float64[]\nAU = Float64[]\nc = zeros(n)\nl = zeros(n)  # x >= 0 (non-negative LASSO)\nu = fill(Inf, n)\n\n# Solve\nmodel = build_from_QAbc(Q_lasso, A_constr, c, AL, AU, l, u)\n\nparams = HPRQP_parameters()\nresult = optimize(model, params)\n\n# Compare to true solution\nx_recovered = result.x\nprintln(\"Recovery error: \", norm(x_recovered - x_true))\nprintln(\"Support recovery: \", sum((abs.(x_recovered) .> 1e-3) .& (abs.(x_true) .> 0)))","category":"section"},{"location":"guide/lasso_problems/#Choosing-the-Regularization-Parameter-λ","page":"LASSO Problems","title":"Choosing the Regularization Parameter λ","text":"The regularization parameter λ controls the sparsity-accuracy trade-off:\n\nSmall λ: Less regularization, more non-zero coefficients, better fit\nLarge λ: More regularization, sparser solution, worse fit","category":"section"},{"location":"guide/lasso_problems/#Cross-Validation","page":"LASSO Problems","title":"Cross-Validation","text":"using HPRQP\n\nfunction lasso_cv(A, b, λ_values; n_folds=5)\n    m, n = size(A)\n    fold_size = div(m, n_folds)\n    cv_errors = zeros(length(λ_values))\n    \n    for (i, λ) in enumerate(λ_values)\n        fold_errors = zeros(n_folds)\n        \n        for fold in 1:n_folds\n            # Split data\n            test_idx = (fold-1)*fold_size+1 : fold*fold_size\n            train_idx = setdiff(1:m, test_idx)\n            \n            A_train = A[train_idx, :]\n            b_train = b[train_idx]\n            A_test = A[test_idx, :]\n            b_test = b[test_idx]\n            \n            # Solve LASSO on training set\n            Q_lasso = LASSOOperatorCPU(A_train, b_train, λ)\n            model = build_from_QAbc(Q_lasso, sparse(zeros(0,n)), \n                                    zeros(n), Float64[], Float64[], \n                                    fill(-Inf,n), fill(Inf,n))\n            \n            params = HPRQP_parameters()\n            params.verbose = false\n            result = optimize(model, params)\n            \n            # Test error\n            fold_errors[fold] = norm(A_test * result.x - b_test)^2 / length(test_idx)\n        end\n        \n        cv_errors[i] = mean(fold_errors)\n    end\n    \n    best_idx = argmin(cv_errors)\n    return λ_values[best_idx], cv_errors\nend\n\n# Use it\nλ_values = [0.001, 0.01, 0.1, 0.5, 1.0, 5.0]\nλ_best, errors = lasso_cv(A, b, λ_values)\nprintln(\"Best λ: \", λ_best)","category":"section"},{"location":"guide/lasso_problems/#Elastic-Net-Variation","page":"LASSO Problems","title":"Elastic Net Variation","text":"Elastic net combines L1 and L2 regularization:\n\nmin_x quad frac12 Ax - b^2 + lambda_1 x_1 + fraclambda_22 x^2\n\n# Elastic net as modified LASSO\nλ1 = 0.1  # L1 penalty\nλ2 = 0.05  # L2 penalty\n\n# Augment A and b for L2 penalty\nA_aug = vcat(A, sqrt(λ2) * I(n))\nb_aug = vcat(b, zeros(n))\n\nQ_elastic = LASSOOperatorCPU(A_aug, b_aug, λ1)\n\nmodel = build_from_QAbc(Q_elastic, A_constr, c, AL, AU, l, u)","category":"section"},{"location":"guide/lasso_problems/#Applications","page":"LASSO Problems","title":"Applications","text":"","category":"section"},{"location":"guide/lasso_problems/#Feature-Selection","page":"LASSO Problems","title":"Feature Selection","text":"# Select important features from high-dimensional data\nm, n = 100, 1000  # More features than samples!\n\nA = randn(m, n)\nx_sparse = sparsevec(rand(1:n, 10), randn(10), n)  # Only 10 important features\nb = A * x_sparse + 0.1 * randn(m)\n\n# Use LASSO to identify important features\nλ = 0.5\nQ_lasso = LASSOOperatorCPU(A, b, λ)\nmodel = build_from_QAbc(Q_lasso, sparse(zeros(0,n)), zeros(n), \n                        Float64[], Float64[], fill(-Inf,n), fill(Inf,n))\n\nparams = HPRQP_parameters()\nresult = optimize(model, params)\n\n# Identify selected features\nthreshold = 1e-4\nselected_features = findall(abs.(result.x) .> threshold)\nprintln(\"Selected \", length(selected_features), \" out of \", n, \" features\")","category":"section"},{"location":"guide/lasso_problems/#Compressed-Sensing","page":"LASSO Problems","title":"Compressed Sensing","text":"# Recover sparse signal from compressed measurements\nn = 1000  # Signal dimension\nm = 200   # Number of measurements (m << n)\nk = 20    # Sparsity level\n\n# Measurement matrix (random Gaussian)\nA = randn(m, n) / sqrt(m)\n\n# Sparse signal\nx_true = sparsevec(rand(1:n, k), randn(k), n)\n\n# Compressed measurements\nb = A * x_true\n\n# Recover using LASSO\nλ = 0.01\nQ_lasso = LASSOOperatorCPU(A, b, λ)\nmodel = build_from_QAbc(Q_lasso, sparse(zeros(0,n)), zeros(n),\n                        Float64[], Float64[], fill(-Inf,n), fill(Inf,n))\n\nparams = HPRQP_parameters()\nresult = optimize(model, params)\n\nprintln(\"Recovery error: \", norm(result.x - x_true) / norm(x_true))","category":"section"},{"location":"guide/lasso_problems/#Time-Series-(Trend-Filtering)","page":"LASSO Problems","title":"Time Series (Trend Filtering)","text":"# LASSO with finite difference regularization\nT = 200  # Time points\ny = sin.(range(0, 2π, length=T)) + 0.2 * randn(T)\n\n# Identity observation\nA = Matrix(1.0I, T, T)\nb = y\n\n# But add constraint on differences (trend filtering)\n# This is approximated using LASSO on transformed space\n\nλ = 0.1\nQ_lasso = LASSOOperatorCPU(A, b, λ)\nmodel = build_from_QAbc(Q_lasso, sparse(zeros(0,T)), zeros(T),\n                        Float64[], Float64[], fill(-Inf,T), fill(Inf,T))\n\nresult = optimize(model, HPRQP_parameters())\nx_smooth = result.x\n\nusing Plots\nplot(y, label=\"Noisy\", alpha=0.5)\nplot!(x_smooth, label=\"LASSO smoothed\", linewidth=2)","category":"section"},{"location":"guide/lasso_problems/#Performance-Tips","page":"LASSO Problems","title":"Performance Tips","text":"GPU Acceleration: LASSO operator benefits significantly from GPU for large problems\nparams = HPRQP_parameters()\nparams.use_gpu = true\nScaling: Standardize features for better numerical behavior\n# Standardize columns of A\nA_mean = mean(A, dims=1)\nA_std = std(A, dims=1)\nA_scaled = (A .- A_mean) ./ A_std\nWarm-start: Solve for sequence of λ values using warm-start\nλ_path = [1.0, 0.5, 0.1, 0.05, 0.01]\nsolutions = []\n\nfor λ in λ_path\n    Q_lasso = LASSOOperatorCPU(A, b, λ)\n    model = build_from_QAbc(Q_lasso, ...)\n    \n    params = HPRQP_parameters()\n    if !isempty(solutions)\n        params.initial_x = solutions[end]  # Warm-start\n    end\n    \n    result = optimize(model, params)\n    push!(solutions, result.x)\nend","category":"section"},{"location":"guide/lasso_problems/#See-Also","page":"LASSO Problems","title":"See Also","text":"Q Operators Overview - Understanding Q operators\nSparse Matrix QP - Alternative general approach\nDirect API - Building models","category":"section"},{"location":"guide/jump_integration/#JuMP-Integration","page":"JuMP Integration","title":"JuMP Integration","text":"HPRQP integrates seamlessly with JuMP through the MathOptInterface (MOI), allowing you to use HPRQP as a backend solver for JuMP models with quadratic objectives.","category":"section"},{"location":"guide/jump_integration/#Basic-Usage","page":"JuMP Integration","title":"Basic Usage","text":"using JuMP\nusing HPRQP\n\nmodel = Model(HPRQP.Optimizer)\n\n@variable(model, x >= 0)\n@variable(model, y >= 0)\n@objective(model, Min, x^2 + 0.5*x*y + y^2 - 3x - 5y)\n@constraint(model, x + 2y <= 10)\n@constraint(model, 3x + y <= 12)\n\noptimize!(model)\n\nprintln(\"Optimal value: \", objective_value(model))\nprintln(\"x = \", value(x), \", y = \", value(y))","category":"section"},{"location":"guide/jump_integration/#Setting-Solver-Attributes","page":"JuMP Integration","title":"Setting Solver Attributes","text":"","category":"section"},{"location":"guide/jump_integration/#Using-set_optimizer_attribute","page":"JuMP Integration","title":"Using set_optimizer_attribute","text":"model = Model(HPRQP.Optimizer)\n\n# Standard MOI attributes\nset_silent(model)                      # Suppress output\nset_time_limit_sec(model, 3600.0)     # 1 hour time limit\n\n# HPRQP-specific attributes\nset_optimizer_attribute(model, \"stoptol\", 1e-6)\nset_optimizer_attribute(model, \"use_gpu\", true)\nset_optimizer_attribute(model, \"device_number\", 0)\nset_optimizer_attribute(model, \"use_Ruiz_scaling\", true)\nset_optimizer_attribute(model, \"warm_up\", true)\nset_optimizer_attribute(model, \"max_iter\", 100000)\n\n# New features: warm-start and auto-save\nset_optimizer_attribute(model, \"initial_x\", x0)  # Warm-start primal\nset_optimizer_attribute(model, \"initial_y\", y0)  # Warm-start dual\nset_optimizer_attribute(model, \"auto_save\", true)\nset_optimizer_attribute(model, \"save_filename\", \"qp_optimization.h5\")\n\ntip: Parameter Reference\nFor detailed explanations of all parameters, see the Parameters guide.","category":"section"},{"location":"guide/jump_integration/#Querying-Results","page":"JuMP Integration","title":"Querying Results","text":"","category":"section"},{"location":"guide/jump_integration/#Termination-Status","page":"JuMP Integration","title":"Termination Status","text":"optimize!(model)\n\nstatus = termination_status(model)\n\nif status == MOI.OPTIMAL\n    println(\"Optimal solution found!\")\nelseif status == MOI.TIME_LIMIT\n    println(\"Time limit reached\")\nelseif status == MOI.ITERATION_LIMIT\n    println(\"Iteration limit reached\")\nend","category":"section"},{"location":"guide/jump_integration/#Objective-and-Solutions","page":"JuMP Integration","title":"Objective and Solutions","text":"if has_values(model)\n    obj_val = objective_value(model)\n    x_val = value(x)\n    y_val = value(y)\n    \n    println(\"Objective: $obj_val\")\n    println(\"x = $x_val, y = $y_val\")\nend","category":"section"},{"location":"guide/jump_integration/#Solve-Time","page":"JuMP Integration","title":"Solve Time","text":"time = solve_time(model)\nprintln(\"Solved in $time seconds\")","category":"section"},{"location":"guide/jump_integration/#Silent-Mode","page":"JuMP Integration","title":"Silent Mode","text":"Suppress all solver output:\n\nmodel = Model(HPRQP.Optimizer)\nset_silent(model)\n\n# Build model...\noptimize!(model)\n# No output from solver\n\nOr equivalently:\n\nmodel = Model(HPRQP.Optimizer)\nset_optimizer_attribute(model, \"verbose\", false)\noptimize!(model)","category":"section"},{"location":"guide/jump_integration/#Common-Patterns","page":"JuMP Integration","title":"Common Patterns","text":"","category":"section"},{"location":"guide/jump_integration/#Portfolio-Optimization","page":"JuMP Integration","title":"Portfolio Optimization","text":"using JuMP, HPRQP\nusing LinearAlgebra\n\n# Historical returns for assets\nreturns = [0.12, 0.10, 0.08, 0.15, 0.09]\nn_assets = length(returns)\n\n# Covariance matrix\nΣ = [0.04 0.01 0.01 0.02 0.01;\n     0.01 0.03 0.01 0.01 0.01;\n     0.01 0.01 0.02 0.01 0.00;\n     0.02 0.01 0.01 0.05 0.02;\n     0.01 0.01 0.00 0.02 0.03]\n\n# Risk aversion\nγ = 2.0\n\nmodel = Model(HPRQP.Optimizer)\nset_silent(model)\n\n@variable(model, w[1:n_assets] >= 0)\n@constraint(model, sum(w) == 1)\n\n# Mean-variance objective\n@objective(model, Max, \n    sum(returns[i] * w[i] for i in 1:n_assets) - \n    γ * sum(Σ[i,j] * w[i] * w[j] for i in 1:n_assets, j in 1:n_assets)\n)\n\noptimize!(model)\n\nif termination_status(model) == MOI.OPTIMAL\n    println(\"Optimal Portfolio:\")\n    for i in 1:n_assets\n        if value(w[i]) > 1e-4\n            println(\"  Asset $i: \", round(value(w[i])*100, digits=2), \"%\")\n        end\n    end\nend","category":"section"},{"location":"guide/jump_integration/#Ridge-Regression","page":"JuMP Integration","title":"Ridge Regression","text":"using JuMP, HPRQP\n\n# Data: X is m×n feature matrix, y is m-vector of responses\nm, n = 100, 20\nX = randn(m, n)\ny = randn(m)\nλ = 0.1  # Regularization parameter\n\nmodel = Model(HPRQP.Optimizer)\nset_silent(model)\n\n@variable(model, β[1:n])\n\n# Ridge objective: ||Xβ - y||² + λ||β||²\n@objective(model, Min, \n    sum((sum(X[i,j]*β[j] for j in 1:n) - y[i])^2 for i in 1:m) +\n    λ * sum(β[j]^2 for j in 1:n)\n)\n\noptimize!(model)\n\nif termination_status(model) == MOI.OPTIMAL\n    β_opt = value.(β)\n    println(\"Ridge regression coefficients: \", β_opt)\nend","category":"section"},{"location":"guide/jump_integration/#Quadratic-Assignment-Problem-(Relaxation)","page":"JuMP Integration","title":"Quadratic Assignment Problem (Relaxation)","text":"using JuMP, HPRQP\n\n# QAP: Assign n facilities to n locations\nn = 5\n\n# Flow matrix (traffic between facilities)\nF = rand(n, n)\nF = F + F'  # Make symmetric\n\n# Distance matrix (distance between locations)\nD = rand(n, n)\nD = D + D'  # Make symmetric\n\nmodel = Model(HPRQP.Optimizer)\nset_silent(model)\n\n# Relaxation: x[i,j] ∈ [0,1] instead of {0,1}\n@variable(model, 0 <= x[i=1:n, j=1:n] <= 1)\n\n# Each facility to exactly one location\nfor i in 1:n\n    @constraint(model, sum(x[i,j] for j in 1:n) == 1)\nend\n\n# Each location gets exactly one facility\nfor j in 1:n\n    @constraint(model, sum(x[i,j] for i in 1:n) == 1)\nend\n\n# QAP objective\n@objective(model, Min,\n    sum(F[i,k] * D[j,l] * x[i,j] * x[k,l] \n        for i in 1:n, j in 1:n, k in 1:n, l in 1:n)\n)\n\noptimize!(model)\n\nif termination_status(model) == MOI.OPTIMAL\n    println(\"QAP relaxation value: \", objective_value(model))\nend","category":"section"},{"location":"guide/jump_integration/#Support-Vector-Machine-(SVM)","page":"JuMP Integration","title":"Support Vector Machine (SVM)","text":"using JuMP, HPRQP\n\n# Binary classification data\nm = 50  # Number of samples\nn = 10  # Number of features\nX = randn(m, n)\ny = rand([-1, 1], m)  # Binary labels\nC = 1.0  # Regularization parameter\n\nmodel = Model(HPRQP.Optimizer)\nset_silent(model)\n\n@variable(model, w[1:n])\n@variable(model, b)\n@variable(model, ξ[1:m] >= 0)  # Slack variables\n\n# Soft-margin SVM\n@constraint(model, [i=1:m], y[i] * (sum(X[i,j]*w[j] for j in 1:n) + b) >= 1 - ξ[i])\n\n@objective(model, Min, \n    0.5 * sum(w[j]^2 for j in 1:n) + C * sum(ξ[i] for i in 1:m)\n)\n\noptimize!(model)\n\nif termination_status(model) == MOI.OPTIMAL\n    println(\"SVM trained successfully!\")\n    w_opt = value.(w)\n    b_opt = value(b)\nend","category":"section"},{"location":"guide/jump_integration/#Reading-MPS-Files-with-JuMP","page":"JuMP Integration","title":"Reading MPS Files with JuMP","text":"You can read MPS files and solve them with HPRQP via JuMP:\n\nusing JuMP, HPRQP\n\nmodel = read_from_file(\"qp_problem.mps\")\nset_optimizer(model, HPRQP.Optimizer)\n\n# Set attributes\nset_optimizer_attribute(model, \"stoptol\", 1e-6)\n\n# Solve\noptimize!(model)\n\nprintln(\"Status: \", termination_status(model))\nif has_values(model)\n    println(\"Objective: \", objective_value(model))\nend","category":"section"},{"location":"guide/jump_integration/#Warm-Starting-with-JuMP","page":"JuMP Integration","title":"Warm-Starting with JuMP","text":"using JuMP, HPRQP\n\n# Solve initial problem\nmodel1 = Model(HPRQP.Optimizer)\n@variable(model1, x >= 0)\n@variable(model1, y >= 0)\n@objective(model1, Min, x^2 + y^2 - 4x - 6y)\n@constraint(model1, x + y <= 5)\n\noptimize!(model1)\nx_sol = value(x)\ny_sol = value(y)\n\n# Solve modified problem with warm-start\nmodel2 = Model(HPRQP.Optimizer)\n@variable(model2, x >= 0)\n@variable(model2, y >= 0)\n@objective(model2, Min, x^2 + y^2 - 4x - 6y)\n@constraint(model2, x + y <= 6)  # Modified constraint\n\n# Warm-start from previous solution\nset_optimizer_attribute(model2, \"initial_x\", [x_sol, y_sol])\n\noptimize!(model2)","category":"section"},{"location":"guide/jump_integration/#See-Also","page":"JuMP Integration","title":"See Also","text":"Parameters - All available solver parameters\nExamples - More complete examples\nDirect API - Lower-level matrix interface","category":"section"},{"location":"guide/output_results/#Output-and-Results","page":"Output & Results","title":"Output & Results","text":"This guide explains how to interpret the results returned by HPRQP solvers and understand the termination status.","category":"section"},{"location":"guide/output_results/#Result-Fields-Summary","page":"Output & Results","title":"Result Fields Summary","text":"All HPRQP solving functions return an HPRQP_results object with the following fields:\n\nField Type Description\nstatus String Termination status: \"OPTIMAL\", \"MAX_ITER\", or \"TIME_LIMIT\"\nx Vector{Float64} Primal solution (decision variables)\ny Vector{Float64} Dual variables for constraints\nz Vector{Float64} Dual variables for bounds\nprimal_obj Float64 Primal objective value (c^T x + c_0)\niter Int Total number of iterations\ntime Float64 Total solve time (seconds)\niter_4, time_4 Int, Float64 Iterations/time to reach 1e-4 accuracy\niter_6, time_6 Int, Float64 Iterations/time to reach 1e-6 accuracy\niter_8, time_8 Int, Float64 Iterations/time to reach 1e-8 accuracy\nresiduals Float64 Combined measure of constraint violations and objective gap\ngap Float64 Objective gap between primal and dual","category":"section"},{"location":"guide/output_results/#Basic-Usage","page":"Output & Results","title":"Basic Usage","text":"result = run_lp(A, AL, AU, c, l, u, c0, params)\n\n# Access results\nprintln(\"Status: \", result.status)\nprintln(\"Objective: \", result.primal_obj)\nprintln(\"Solution: \", result.x)\nprintln(\"Time: \", result.time, \" seconds\")","category":"section"},{"location":"guide/output_results/#Result-Fields","page":"Output & Results","title":"Result Fields","text":"","category":"section"},{"location":"guide/output_results/#Termination-Status","page":"Output & Results","title":"Termination Status","text":"","category":"section"},{"location":"guide/output_results/#status::String","page":"Output & Results","title":"status::String","text":"Indicates why the solver stopped:\n\n\"OPTIMAL\" - Successfully found an optimal solution within tolerance\n\"MAX_ITER\" - Reached maximum iteration limit before converging\n\"TIME_LIMIT\" - Reached time limit before converging\n\nif result.status == \"OPTIMAL\"\n    println(\"✓ Optimal solution found!\")\n    println(\"Objective value: \", result.primal_obj)\nelseif result.status == \"MAX_ITER\"\n    println(\"⚠ Iteration limit reached\")\n    println(\"Best objective: \", result.primal_obj)\n    println(\"Residual: \", result.residuals)\nelseif result.status == \"TIME_LIMIT\"\n    println(\"⚠ Time limit reached\")\n    println(\"Best objective: \", result.primal_obj)\nend","category":"section"},{"location":"guide/output_results/#Solution-Vectors","page":"Output & Results","title":"Solution Vectors","text":"","category":"section"},{"location":"guide/output_results/#x::Vector{Float64}","page":"Output & Results","title":"x::Vector{Float64}","text":"The primal solution vector (decision variables).\n\n# Access solution values\nprintln(\"x₁ = \", result.x[1])\nprintln(\"x₂ = \", result.x[2])\n\n# Use in calculations\noptimal_cost = sum(c .* result.x)","category":"section"},{"location":"guide/output_results/#y::Vector{Float64}","page":"Output & Results","title":"y::Vector{Float64}","text":"The dual variables for constraints.","category":"section"},{"location":"guide/output_results/#z::Vector{Float64}","page":"Output & Results","title":"z::Vector{Float64}","text":"The dual variables for bound constraints (reduced costs).","category":"section"},{"location":"guide/output_results/#Objective-Values","page":"Output & Results","title":"Objective Values","text":"","category":"section"},{"location":"guide/output_results/#primal_obj::Float64","page":"Output & Results","title":"primal_obj::Float64","text":"The primal objective value: c^T x + c_0\n\nprintln(\"Optimal cost: \", result.primal_obj)","category":"section"},{"location":"guide/output_results/#Performance-Metrics","page":"Output & Results","title":"Performance Metrics","text":"","category":"section"},{"location":"guide/output_results/#iter::Int","page":"Output & Results","title":"iter::Int","text":"Total number of iterations performed.\n\nprintln(\"Solved in \", result.iter, \" iterations\")","category":"section"},{"location":"guide/output_results/#time::Float64","page":"Output & Results","title":"time::Float64","text":"Total solve time in seconds (excluding setup and scaling).\n\nprintln(\"Solve time: \", result.time, \" seconds\")","category":"section"},{"location":"guide/output_results/#Accuracy-Milestones","page":"Output & Results","title":"Accuracy Milestones","text":"HPRQP tracks when certain accuracy levels are reached:\n\niter_4, time_4 - Iterations/time to reach 1e-4 accuracy\niter_6, time_6 - Iterations/time to reach 1e-6 accuracy  \niter_8, time_8 - Iterations/time to reach 1e-8 accuracy\n\nif result.time_6 < params.time_limit\n    println(\"Reached 1e-6 accuracy in \", result.iter_6, \" iterations\")\n    println(\"Time to 1e-6: \", result.time_6, \" seconds\")\nend","category":"section"},{"location":"guide/output_results/#Quality-Metrics","page":"Output & Results","title":"Quality Metrics","text":"","category":"section"},{"location":"guide/output_results/#residuals::Float64","page":"Output & Results","title":"residuals::Float64","text":"Combined measure of constraint violations and objective gap. Lower is better.\n\nprintln(\"Final residual: \", result.residuals)","category":"section"},{"location":"guide/output_results/#gap::Float64","page":"Output & Results","title":"gap::Float64","text":"Objective gap between primal and dual solutions.\n\nprintln(\"Objective gap: \", result.gap)","category":"section"},{"location":"guide/output_results/#Checking-Solution-Quality","page":"Output & Results","title":"Checking Solution Quality","text":"","category":"section"},{"location":"guide/output_results/#Optimal-Solutions","page":"Output & Results","title":"Optimal Solutions","text":"function check_solution_quality(result, params)\n    if result.status != \"OPTIMAL\"\n        @warn \"Solution not optimal: $(result.status)\"\n    end\n    \n    if result.residuals > params.stoptol\n        @warn \"Residuals exceed tolerance: $(result.residuals) > $(params.stoptol)\"\n    end\n    \n    if result.gap > 1e-3\n        @warn \"Large objective gap: $(result.gap)\"\n    end\n    \n    return result.status == \"OPTIMAL\" && \n           result.residuals <= params.stoptol\nend","category":"section"},{"location":"guide/output_results/#Verifying-Feasibility","page":"Output & Results","title":"Verifying Feasibility","text":"function verify_primal_feasibility(result, A, AL, AU, l, u)\n    x = result.x\n    \n    # Check variable bounds\n    if any(x .< l .- 1e-6) || any(x .> u .+ 1e-6)\n        @warn \"Variable bounds violated\"\n        return false\n    end\n    \n    # Check constraint bounds\n    Ax = A * x\n    if any(Ax .< AL .- 1e-6) || any(Ax .> AU .+ 1e-6)\n        @warn \"Constraint bounds violated\"\n        return false\n    end\n    \n    println(\"✓ Solution is feasible\")\n    return true\nend","category":"section"},{"location":"guide/output_results/#Examples","page":"Output & Results","title":"Examples","text":"","category":"section"},{"location":"guide/output_results/#Basic-Usage-2","page":"Output & Results","title":"Basic Usage","text":"using HPRQP\n\nparams = HPRQP_parameters()\nresult = run_single(\"problem.mps\", params)\n\nprintln(\"═══════ Solution Summary ═══════\")\nprintln(\"Status:     \", result.status)\nprintln(\"Objective:  \", result.primal_obj)\nprintln(\"Iterations: \", result.iter)\nprintln(\"Time:       \", round(result.time, digits=3), \" sec\")\nprintln(\"Residual:   \", result.residuals)\nprintln(\"════════════════════════════════\")","category":"section"},{"location":"guide/output_results/#Detailed-Analysis","page":"Output & Results","title":"Detailed Analysis","text":"function analyze_results(result, params)\n    println(\"\\n\" * \"=\"^50)\n    println(\"HPRQP Solution Analysis\")\n    println(\"=\"^50)\n    \n    # Termination status\n    println(\"\\n[Termination]\")\n    println(\"  Status: \", result.status)\n    \n    # Objective information\n    println(\"\\n[Objective]\")\n    println(\"  Primal: \", result.primal_obj)\n    println(\"  Gap:    \", result.gap)\n    \n    # Performance\n    println(\"\\n[Performance]\")\n    println(\"  Iterations: \", result.iter)\n    println(\"  Time:       \", round(result.time, digits=3), \" seconds\")\n    \n    # Accuracy milestones\n    println(\"\\n[Accuracy Milestones]\")\n    if result.iter_4 > 0\n        println(\"  1e-4: \", result.iter_4, \" iterations, \", \n                round(result.time_4, digits=3), \" sec\")\n    end\n    if result.iter_6 > 0\n        println(\"  1e-6: \", result.iter_6, \" iterations, \", \n                round(result.time_6, digits=3), \" sec\")\n    end\n    if result.iter_8 > 0\n        println(\"  1e-8: \", result.iter_8, \" iterations, \", \n                round(result.time_8, digits=3), \" sec\")\n    end\n    \n    # Quality assessment\n    println(\"\\n[Solution Quality]\")\n    println(\"  Residual:  \", result.residuals)\n    println(\"  Tolerance: \", params.stoptol)\n    \n    quality = if result.residuals < params.stoptol / 10\n        \"Excellent\"\n    elseif result.residuals < params.stoptol\n        \"Good\"\n    elseif result.residuals < params.stoptol * 10\n        \"Acceptable\"\n    else\n        \"Poor\"\n    end\n    println(\"  Quality:   \", quality)\n    \n    println(\"=\"^50 * \"\\n\")\nend\n\n# Usage\nresult = run_single(\"model.mps\", params)\nanalyze_results(result, params)","category":"section"},{"location":"guide/output_results/#Comparing-Solutions","page":"Output & Results","title":"Comparing Solutions","text":"function compare_results(result1, result2, label1=\"Result 1\", label2=\"Result 2\")\n    println(\"\\n\", \"=\"^60)\n    println(\"Solution Comparison\")\n    println(\"=\"^60)\n    \n    println(\"\\n\", rpad(\"Metric\", 20), rpad(label1, 20), label2)\n    println(\"-\"^60)\n    \n    println(rpad(\"Status\", 20), \n            rpad(result1.status, 20), result2.status)\n    println(rpad(\"Objective\", 20), \n            rpad(string(round(result1.primal_obj, digits=6)), 20),\n            round(result2.primal_obj, digits=6))\n    println(rpad(\"Iterations\", 20), \n            rpad(string(result1.iter), 20), result2.iter)\n    println(rpad(\"Time (sec)\", 20), \n            rpad(string(round(result1.time, digits=3)), 20),\n            round(result2.time, digits=3))\n    println(rpad(\"Residual\", 20), \n            rpad(string(result1.residuals), 20), result2.residuals)\n    \n    println(\"=\"^60 * \"\\n\")\nend\n\n# Usage: Compare GPU vs CPU\nparams_gpu = HPRQP_parameters()\nparams_gpu.use_gpu = true\n\nparams_cpu = HPRQP_parameters()\nparams_cpu.use_gpu = false\n\nresult_gpu = run_single(\"model.mps\", params_gpu)\nresult_cpu = run_single(\"model.mps\", params_cpu)\n\ncompare_results(result_gpu, result_cpu, \"GPU\", \"CPU\")","category":"section"},{"location":"guide/output_results/#Common-Issues","page":"Output & Results","title":"Common Issues","text":"","category":"section"},{"location":"guide/output_results/#Non-Optimal-Termination","page":"Output & Results","title":"Non-Optimal Termination","text":"If solver stops with MAX_ITER or TIME_LIMIT:\n\nif result.status != \"OPTIMAL\"\n    # Check if close to optimal\n    if result.residuals < 1e-3\n        println(\"Near-optimal solution found\")\n        println(\"Consider increasing time_limit or max_iter\")\n    else\n        println(\"Poor solution quality\")\n        println(\"Problem may be ill-conditioned\")\n        println(\"Try adjusting scaling parameters\")\n    end\nend","category":"section"},{"location":"guide/output_results/#Large-Residuals","page":"Output & Results","title":"Large Residuals","text":"if result.residuals > params.stoptol * 100\n    @warn \"Very large residuals - possible issues:\"\n    println(\"  - Problem may be infeasible or unbounded\")\n    println(\"  - Numerical scaling issues\")\n    println(\"  - Try enabling all scaling options\")\n    println(\"  - Check problem formulation\")\nend","category":"section"},{"location":"getting_started/#Getting-Started","page":"Getting Started","title":"Getting Started","text":"","category":"section"},{"location":"getting_started/#Prerequisites","page":"Getting Started","title":"Prerequisites","text":"Before using HPRQP, ensure you have:\n\nJulia (version 1.10 or higher recommended)\nCUDA (optional, for GPU acceleration)\nCUDA Toolkit 12.4 or higher for best compatibility","category":"section"},{"location":"getting_started/#Installation","page":"Getting Started","title":"Installation","text":"","category":"section"},{"location":"getting_started/#From-GitHub","page":"Getting Started","title":"From GitHub","text":"using Pkg\nPkg.add(url=\"https://github.com/PolyU-IOR/HPR-QP\")","category":"section"},{"location":"getting_started/#Development-Installation","page":"Getting Started","title":"Development Installation","text":"To install for development:\n\ngit clone https://github.com/PolyU-IOR/HPR-QP.git\ncd HPR-QP\njulia --project -e 'using Pkg; Pkg.instantiate()'","category":"section"},{"location":"getting_started/#Verifying-CUDA-Installation","page":"Getting Started","title":"Verifying CUDA Installation","text":"If you plan to use GPU acceleration, verify CUDA is working:\n\nusing CUDA\nCUDA.versioninfo()\n\nIf CUDA is not available, HPRQP will automatically fall back to CPU mode.","category":"section"},{"location":"getting_started/#First-Example:-Solving-a-Simple-QP","page":"Getting Started","title":"First Example: Solving a Simple QP","text":"Let's solve a basic quadratic programming problem:\n\nbeginarrayll\nmin quad  frac12(2x_1^2 + x_1x_2 + 2x_2^2) - 3x_1 - 5x_2 \ntextst quad  x_1 + 2x_2 leq 10 \n 3x_1 + x_2 leq 12 \n x_1 x_2 geq 0\nendarray","category":"section"},{"location":"getting_started/#Using-the-Direct-API","page":"Getting Started","title":"Using the Direct API","text":"using HPRQP\nusing SparseArrays\n\n# Define the quadratic objective: 0.5*x'*Q*x + c'*x\nQ = sparse([2.0 0.5; 0.5 2.0])\nc = [-3.0, -5.0]\n\n# Convert constraints to standard form: AL ≤ Ax ≤ AU\nA = sparse([-1.0 -2.0; -3.0 -1.0])\nAL = [-10.0, -12.0]\nAU = [Inf, Inf]\nl = [0.0, 0.0]\nu = [Inf, Inf]\n\n# Step 1: Build the model\nmodel = build_from_QAbc(Q, A, c, AL, AU, l, u)\n\n# Step 2: Set up parameters\nparams = HPRQP_parameters()\nparams.use_gpu = false      # Use CPU for this small problem\nparams.stoptol = 1e-4       # Convergence tolerance\nparams.time_limit = 60      # Maximum 60 seconds\nparams.verbose = true       # Print solver output\n\n# Step 3: Solve\nresult = optimize(model, params)\n\n# Check results\nprintln(\"Status: \", result.status)\nprintln(\"Optimal value: \", result.primal_obj)\nprintln(\"Solution: x₁ = \", result.x[1], \", x₂ = \", result.x[2])\nprintln(\"Iterations: \", result.iter)\nprintln(\"Solve time: \", result.time, \" seconds\")","category":"section"},{"location":"getting_started/#Using-JuMP","page":"Getting Started","title":"Using JuMP","text":"The same problem using the JuMP modeling interface:\n\nusing JuMP\nusing HPRQP\n\nmodel = Model(HPRQP.Optimizer)\n\n# Set optimizer attributes\nset_optimizer_attribute(model, \"stoptol\", 1e-4)\nset_optimizer_attribute(model, \"use_gpu\", false)\nset_optimizer_attribute(model, \"verbose\", true)\n\n# Define variables and constraints\n@variable(model, x1 >= 0)\n@variable(model, x2 >= 0)\n@objective(model, Min, x1^2 + 0.5*x1*x2 + x2^2 - 3x1 - 5x2)\n@constraint(model, x1 + 2x2 <= 10)\n@constraint(model, 3x1 + x2 <= 12)\n\n# Solve\noptimize!(model)\n\n# Get results\nprintln(\"Status: \", termination_status(model))\nprintln(\"Optimal value: \", objective_value(model))\nprintln(\"Solution: x₁ = \", value(x1), \", x₂ = \", value(x2))\nprintln(\"Solve time: \", solve_time(model), \" seconds\")","category":"section"},{"location":"getting_started/#Solve-from-MPS-Files","page":"Getting Started","title":"Solve from MPS Files","text":"using HPRQP\n\n# Build model from file (for QP problems in MPS format)\nmodel = build_from_mps(\"model.mps\")\n\n# Set parameters\nparams = HPRQP_parameters()\n\n# Solve\nresult = optimize(model, params)","category":"section"},{"location":"getting_started/#Next-Steps","page":"Getting Started","title":"Next Steps","text":"Learn about solving MPS files\nExplore the Direct API in detail\nSee more JuMP integration examples\nUnderstand Q Operators for different problem types\nCheck out the full API Reference\nBrowse additional Examples","category":"section"},{"location":"getting_started/#Performance-Tips","page":"Getting Started","title":"Performance Tips","text":"JIT Compilation: The first run will be slow due to Julia's JIT compilation. For benchmarking, run the solver twice or use a warm-up phase.\nGPU Usage: For large problems (typically > 10,000 variables/constraints), GPU acceleration can provide significant speedups.\nScaling: The default scaling methods (Ruiz and Pock-Chambolle) improve numerical stability. Keep them enabled unless you have specific reasons to disable them.\nTolerance: The default stoptol = 1e-4 is relatively loose. Increase for more accurate solutions in critical applications.\nQ Operator Selection: Choose the appropriate Q operator for your problem structure (sparse matrix, LASSO, QAP) for best performance.","category":"section"},{"location":"examples/#Examples","page":"Examples","title":"Examples","text":"Complete, runnable examples demonstrating HPRQP usage. More examples coming soon!\n\nFor detailed guides on each input method, see:\n\nDirect API Guide\nJuMP Integration Guide  \nMPS Files Guide\nQ Operators Overview","category":"section"},{"location":"examples/#Example-1:-Direct-API-Basic-QP","page":"Examples","title":"Example 1: Direct API - Basic QP","text":"Solve a simple 2-variable QP problem using matrices.\n\nusing HPRQP\nusing SparseArrays\n\n# Problem:\n# min  0.5*(2x₁² + x₁x₂ + 2x₂²) - 3x₁ - 5x₂\n# s.t.  x₁ + 2x₂ ≤ 10\n#      3x₁ +  x₂ ≤ 12\n#      x₁, x₂ ≥ 0\n\n# Quadratic and linear terms\nQ = sparse([2.0 0.5; 0.5 2.0])\nc = [-3.0, -5.0]\n\n# Standard form: AL ≤ Ax ≤ AU\nA = sparse([-1.0 -2.0; -3.0 -1.0])\nAL = [-10.0, -12.0]\nAU = [Inf, Inf]\nl = [0.0, 0.0]\nu = [Inf, Inf]\n\n# Build and solve\nmodel = build_from_QAbc(Q, A, c, AL, AU, l, u)\n\nparams = HPRQP_parameters()\nparams.use_gpu = false\n\nresult = optimize(model, params)\n\nprintln(\"Status: \", result.status)\nprintln(\"Objective: \", result.primal_obj)\nprintln(\"Solution: x₁ = \", result.x[1], \", x₂ = \", result.x[2])","category":"section"},{"location":"examples/#Example-2:-MPS-Files","page":"Examples","title":"Example 2: MPS Files","text":"Read and solve a QP problem from an MPS file.\n\nusing HPRQP\n\n# Build model from file\nmodel = build_from_mps(\"qp_problem.mps\")\n\n# Configure parameters\nparams = HPRQP_parameters()\nparams.stoptol = 1e-6\nparams.use_gpu = true\nparams.verbose = true\n\n# Solve\nresult = optimize(model, params)\n\nif result.status == \"OPTIMAL\"\n    println(\"✓ Optimal solution found!\")\n    println(\"  Objective: \", result.primal_obj)\n    println(\"  Time: \", result.time, \" seconds\")\nend","category":"section"},{"location":"examples/#Example-3:-JuMP-Integration","page":"Examples","title":"Example 3: JuMP Integration","text":"Build and solve using JuMP's modeling language.\n\nusing JuMP, HPRQP\n\nmodel = Model(HPRQP.Optimizer)\nset_optimizer_attribute(model, \"stoptol\", 1e-4)\n\n@variable(model, x1 >= 0)\n@variable(model, x2 >= 0)\n@objective(model, Min, x1^2 + 0.5*x1*x2 + x2^2 - 3x1 - 5x2)\n@constraint(model, x1 + 2x2 <= 10)\n@constraint(model, 3x1 + x2 <= 12)\n\noptimize!(model)\n\nprintln(\"Status: \", termination_status(model))\nprintln(\"Objective: \", objective_value(model))\nprintln(\"x1 = \", value(x1), \", x2 = \", value(x2))","category":"section"},{"location":"examples/#Example-4:-LASSO-Problem","page":"Examples","title":"Example 4: LASSO Problem","text":"Solve a LASSO regression problem using the specialized LASSO operator.\n\nusing HPRQP\nusing SparseArrays\n\n# LASSO problem: min 0.5||Ax - b||² + λ||x||₁\n# Reformulated as QP with Q = A'A\n\nm, n = 100, 50\nA_data = randn(m, n)\nb = randn(m)\nλ = 0.1\n\n# Build LASSO operator\nQ_lasso = LASSOOperatorCPU(A_data, b, λ)\n\n# No additional linear constraints (just bounds)\nA = sparse(zeros(0, n))\nAL = Float64[]\nAU = Float64[]\nc = zeros(n)\nl = fill(-Inf, n)\nu = fill(Inf, n)\n\n# Build and solve\nmodel = build_from_QAbc(Q_lasso, A, c, AL, AU, l, u)\n\nparams = HPRQP_parameters()\nparams.use_gpu = true\n\nresult = optimize(model, params)\n\nprintln(\"LASSO solution found!\")\nprintln(\"Sparsity: \", sum(abs.(result.x) .> 1e-6), \" / \", n)","category":"section"},{"location":"examples/#Example-5:-Sparse-Matrix-QP","page":"Examples","title":"Example 5: Sparse Matrix QP","text":"Solve a large sparse QP problem.\n\nusing HPRQP\nusing SparseArrays\n\n# Generate a random sparse positive semidefinite matrix\nn = 1000\ndensity = 0.01\nH = sprandn(n, n, density)\nQ = H' * H  # Make it positive semidefinite\n\nc = randn(n)\n\n# Simple box constraints\nA = sparse(zeros(0, n))\nAL = Float64[]\nAU = Float64[]\nl = fill(-1.0, n)\nu = fill(1.0, n)\n\n# Build and solve\nmodel = build_from_QAbc(Q, A, c, AL, AU, l, u)\n\nparams = HPRQP_parameters()\nparams.use_gpu = true\nparams.stoptol = 1e-4\n\nresult = optimize(model, params)\n\nprintln(\"Solved large sparse QP!\")\nprintln(\"Objective: \", result.primal_obj)\nprintln(\"Time: \", result.time, \" seconds\")","category":"section"},{"location":"examples/#Example-6:-Using-Warm-Start","page":"Examples","title":"Example 6: Using Warm-Start","text":"Solve related problems with warm-start.\n\nusing HPRQP\nusing SparseArrays\n\nQ = sparse([2.0 0.5; 0.5 2.0])\nA = sparse([1.0 2.0; 3.0 1.0])\nc = [-3.0, -5.0]\nAL = [-Inf, -Inf]\nAU = [10.0, 12.0]\nl = [0.0, 0.0]\nu = [Inf, Inf]\n\n# First solve\nmodel = build_from_QAbc(Q, A, c, AL, AU, l, u)\nparams = HPRQP_parameters()\nresult1 = optimize(model, params)\n\n# Solve modified problem with warm-start\nAU_new = [11.0, 12.0]\nmodel2 = build_from_QAbc(Q, A, c, AL, AU_new, l, u)\nparams.initial_x = result1.x\nparams.initial_y = result1.y\nresult2 = optimize(model2, params)\n\nprintln(\"Warm-start improved convergence!\")","category":"section"},{"location":"examples/#Example-7:-Auto-Save-Feature","page":"Examples","title":"Example 7: Auto-Save Feature","text":"Enable auto-save for long optimizations.\n\nusing HPRQP\n\nmodel = build_from_mps(\"large_qp_problem.mps\")\n\nparams = HPRQP_parameters()\nparams.time_limit = 3600\nparams.auto_save = true\nparams.save_filename = \"best_qp_solution.h5\"\n\nresult = optimize(model, params)","category":"section"},{"location":"examples/#Example-8:-Reading-Auto-Saved-Results","page":"Examples","title":"Example 8: Reading Auto-Saved Results","text":"using HDF5\n\nh5open(\"best_qp_solution.h5\", \"r\") do file\n    x_best = read(file, \"x\")\n    y_best = read(file, \"y\")\n    println(\"Best solution found at iteration: \", read(file, \"iter\"))\nend","category":"section"},{"location":"examples/#Example-9:-Portfolio-Optimization","page":"Examples","title":"Example 9: Portfolio Optimization","text":"A classic quadratic programming application.\n\nusing JuMP, HPRQP\nusing Statistics\n\n# Historical returns for 5 assets\nreturns = [0.12, 0.10, 0.08, 0.15, 0.09]\nn_assets = length(returns)\n\n# Covariance matrix (simplified)\nΣ = [0.04 0.01 0.01 0.02 0.01;\n     0.01 0.03 0.01 0.01 0.01;\n     0.01 0.01 0.02 0.01 0.00;\n     0.02 0.01 0.01 0.05 0.02;\n     0.01 0.01 0.00 0.02 0.03]\n\n# Risk aversion parameter\nγ = 2.0\n\nmodel = Model(HPRQP.Optimizer)\nset_silent(model)\n\n@variable(model, w[1:n_assets] >= 0)  # Portfolio weights\n@constraint(model, sum(w) == 1)       # Fully invested\n\n# Objective: maximize return - γ * risk\n@objective(model, Max, \n    sum(returns[i] * w[i] for i in 1:n_assets) - \n    γ * sum(Σ[i,j] * w[i] * w[j] for i in 1:n_assets, j in 1:n_assets)\n)\n\noptimize!(model)\n\nif termination_status(model) == MOI.OPTIMAL\n    println(\"Optimal Portfolio:\")\n    for i in 1:n_assets\n        if value(w[i]) > 1e-4\n            println(\"  Asset $i: \", round(value(w[i])*100, digits=2), \"%\")\n        end\n    end\n    println(\"Expected return: \", sum(returns .* value.(w)))\nend","category":"section"},{"location":"examples/#More-Examples","page":"Examples","title":"More Examples","text":"More examples will be added in future releases.","category":"section"},{"location":"#HPRQP.jl-Documentation","page":"Home","title":"HPRQP.jl Documentation","text":"A Julia implementation of the Halpern Peaceman-Rachford (HPR) method for solving quadratic programming (QP) problems on the GPU.","category":"section"},{"location":"#Overview","page":"Home","title":"Overview","text":"HPRQP.jl is a high-performance quadratic programming solver that leverages GPU acceleration to solve large-scale QP problems efficiently. It implements the Halpern Peaceman-Rachford splitting method with adaptive restart strategy and penalty parameter selection.","category":"section"},{"location":"#Features","page":"Home","title":"Features","text":"✅ GPU Acceleration: Native CUDA support for solving large-scale problems\n✅ CPU Support: Support CPU mode when GPU is not available\n✅ Multiple Inputs: \nDirect API with matrix inputs\nMPS file format support\nJuMP integration via MOI wrapper\n✅ Flexible Q Operators: Support for sparse matrices, LASSO, QAP, and custom operators\n✅ Flexible Scaling: Ruiz, Pock-Chambolle, and scalar scaling methods\n✅ Adaptive Algorithms: Automatic restart strategy and penalty parameter selection","category":"section"},{"location":"#Problem-Formulation","page":"Home","title":"Problem Formulation","text":"HPRQP solves quadratic programming problems of the form:\n\nbeginarrayll\nundersetx in mathbbR^nmin quad  frac12 langle x Qx rangle + langle c x rangle \ntextst quad  L leq A x leq U \n l leq x leq u \nendarray\n\nwhere:\n\nx in mathbbR^n is the decision variable\nQ in mathbbR^n times n is a symmetric positive semidefinite matrix (or operator)\nc in mathbbR^n is the linear objective coefficient vector\nA in mathbbR^m times n is the constraint matrix\nL U in mathbbR^m are lower and upper bounds on constraints\nl u in mathbbR^n are lower and upper bounds on variables","category":"section"},{"location":"#Quick-Start","page":"Home","title":"Quick Start","text":"","category":"section"},{"location":"#Installation","page":"Home","title":"Installation","text":"From GitHub (recommended for applications):\n\nusing Pkg\nPkg.add(url=\"https://github.com/PolyU-IOR/HPR-QP\")\n\nLocally (recommended for development):\n\ngit clone https://github.com/PolyU-IOR/HPR-QP.git\ncd HPR-QP\njulia --project=. -e 'using Pkg; Pkg.instantiate()'","category":"section"},{"location":"#Simple-Example","page":"Home","title":"Simple Example","text":"using HPRQP\nusing SparseArrays\n\n# Define QP: min 0.5*x'*Q*x + c'*x s.t. Ax ≤ b, x ≥ 0\nQ = sparse([2.0 0.5; 0.5 2.0])\nA = sparse([-1.0 -2.0; -3.0 -1.0])\nc = [-3.0, -5.0]\nAL = [-10.0, -12.0]\nAU = [Inf, Inf]\nl = [0.0, 0.0]\nu = [Inf, Inf]\n\n# Build and solve\nmodel = build_from_QAbc(Q, A, c, AL, AU, l, u)\n\nparams = HPRQP_parameters()\nparams.stoptol = 1e-9  # Set stopping tolerance\n\nresult = optimize(model, params)\n\nprintln(\"Optimal value: \", result.primal_obj)\nprintln(\"Solution: x = \", result.x)","category":"section"},{"location":"#With-JuMP","page":"Home","title":"With JuMP","text":"using JuMP, HPRQP\n\nmodel = Model(HPRQP.Optimizer)\n\n@variable(model, x1 >= 0)\n@variable(model, x2 >= 0)\n@objective(model, Min, x1^2 + x1*x2 + x2^2 - 3x1 - 5x2)\n@constraint(model, x1 + 2x2 <= 10)\n@constraint(model, 3x1 + x2 <= 12)\n\nset_attribute(model, \"stoptol\", 1e-9)  # Set stopping tolerance\n\noptimize!(model)\nprintln(\"Objective: \", objective_value(model))\nprintln(\"x1 = \", value(x1), \", x2 = \", value(x2))","category":"section"},{"location":"#Documentation-Contents","page":"Home","title":"Documentation Contents","text":"Pages = [\n    \"getting_started.md\",\n    \"guide/mps_files.md\",\n    \"guide/direct_api.md\",\n    \"guide/jump_integration.md\",\n    \"guide/q_operators_overview.md\",\n    \"guide/sparse_matrix_qp.md\",\n    \"guide/lasso_problems.md\",\n    \"guide/qap_problems.md\",\n    \"api.md\",\n    \"examples.md\",\n]\nDepth = 2","category":"section"},{"location":"#Citation","page":"Home","title":"Citation","text":"If you use HPRQP in your research, please cite:\n\n@article{chen2025hpr,\n  title={HPR-QP: An implementation of an HPR method for solving quadratic programming.},\n  author={Chen, Kaihuang and Sun, Defeng and Yuan, Yancheng and Zhang, Guojun and Zhao, Xinyuan},\n  journal={Mathematical Programming Computation},\n  year={2025},\n  publisher={Springer}\n}","category":"section"},{"location":"#License","page":"Home","title":"License","text":"HPRQP.jl is licensed under the MIT License. See LICENSE for details.","category":"section"}]
}
